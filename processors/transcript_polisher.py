#!/usr/bin/env python3
"""
é€å­—ç¨¿å°ˆæ¥­æ¢³ç†å™¨
å°‡è‡ªå‹•ç”Ÿæˆçš„é€å­—ç¨¿è½‰æ›ç‚ºå°ˆæ¥­ç´šæ–‡æœ¬

åŠŸèƒ½ï¼š
1. æ¸…ç†å…ƒæ•¸æ“šè¡Œ (Kind: captions ç­‰)
2. åˆä½µé›¶æ•£æ®µè½ç‚ºé€£è²«æ–‡æœ¬
3. æ·»åŠ é©ç•¶æ¨™é»ç¬¦è™Ÿ
4. ä¿æŒåŸèªè¨€ä¸è®Š
5. ä¸­æ–‡å…§å®¹è½‰ç¹é«”+å°ç£ç”¨è©
"""

import re
from typing import Optional
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent.parent))

from processors.llm_client import get_llm_client


class TranscriptPolisher:
    """é€å­—ç¨¿å°ˆæ¥­æ¢³ç†å™¨"""
    
    # éœ€è¦æ¸…ç†çš„å…ƒæ•¸æ“šè¡Œæ¨¡å¼
    METADATA_PATTERNS = [
        r'^Kind:\s*.+$',
        r'^Language:\s*.+$',
        r'^WEBVTT$',
        r'^NOTE\s*.*$',
        r'^\d{2}:\d{2}:\d{2}\.\d{3}\s*-->.*$',  # æ™‚é–“æˆ³
        r'^\d+$',  # ç´”åºè™Ÿ
        r'^<c>.*</c>$',  # VTT æ¨™ç±¤
    ]
    
    # è³‡æ·±é€å­—ç¨¿è™•ç†å°ˆå®¶ Prompt
    POLISHER_PROMPT = """ä½ æ˜¯æ“æœ‰ 20 å¹´ç¶“é©—çš„å°ˆæ¥­é€å­—ç¨¿è™•ç†å°ˆå®¶ã€‚

## ä»»å‹™
å°‡ä»¥ä¸‹è‡ªå‹•ç”Ÿæˆçš„é€å­—ç¨¿æ¢³ç†ç‚ºå°ˆæ¥­ç´šæ–‡æœ¬ã€‚

## åš´æ ¼è¦å‰‡
1. **ä¿æŒåŸèªè¨€**ï¼šè‹±æ–‡å…§å®¹ä¿æŒè‹±æ–‡ï¼Œä¸­æ–‡å…§å®¹ä¿æŒä¸­æ–‡ï¼Œçµ•ä¸ç¿»è­¯
2. **åˆä½µæ®µè½**ï¼šå°‡é›¶æ•£çš„å¥å­ç‰‡æ®µåˆä½µç‚ºå®Œæ•´ã€é€£è²«çš„å¥å­
3. **æ·»åŠ æ¨™é»**ï¼šç‚ºæ–‡æœ¬æ·»åŠ é©ç•¶çš„æ¨™é»ç¬¦è™Ÿï¼ˆå¥è™Ÿã€é€—è™Ÿã€å•è™Ÿã€é©šå˜†è™Ÿç­‰ï¼‰
4. **ç§»é™¤å¡«å……è©**ï¼šåˆªé™¤ "um", "uh", "like", "you know", "å—¯", "é‚£å€‹", "å°±æ˜¯èªª" ç­‰å£èªå¡«å……è©
5. **ä¿ç•™èªªè©±è€…æ¨™è¨˜**ï¼šè‹¥åŸæ–‡æœ‰èªªè©±è€…æ¨™è¨˜ï¼ˆå¦‚ã€Œä¸»è¬›è€…:ã€ï¼‰ï¼Œä¿ç•™ä¸¦çµ±ä¸€æ ¼å¼
6. **ä¸å¾—æ”¹å¯«**ï¼šä¸è¦æ”¹å¯«å…§å®¹ã€ä¸è¦æ·»åŠ å…§å®¹ã€ä¸è¦ç¸½çµ
7. **è‡ªç„¶åˆ†æ®µ**ï¼šæ ¹æ“šè©±é¡Œè½‰æ›æˆ–é‚è¼¯åˆ†æ®µï¼Œæ¯æ®µ 3-5 å¥ç‚ºå®œ

## è¼¸å‡ºæ ¼å¼
ç›´æ¥è¼¸å‡ºæ¢³ç†å¾Œçš„ç´”æ–‡æœ¬é€å­—ç¨¿ï¼Œä¸åŠ ä»»ä½•æ¨™é¡Œæˆ–èªªæ˜ã€‚

## å¾…è™•ç†é€å­—ç¨¿
"""

    def __init__(self):
        self.llm = get_llm_client()
    
    def clean_metadata(self, text: str) -> str:
        """æ¸…ç†å…ƒæ•¸æ“šè¡Œ"""
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            stripped = line.strip()
            
            # è·³éç©ºè¡Œé€£çºŒè¶…é 2 è¡Œ
            if not stripped:
                if cleaned_lines and cleaned_lines[-1] == '':
                    continue
                cleaned_lines.append('')
                continue
            
            # æª¢æŸ¥æ˜¯å¦åŒ¹é…å…ƒæ•¸æ“šæ¨¡å¼
            is_metadata = False
            for pattern in self.METADATA_PATTERNS:
                if re.match(pattern, stripped, re.IGNORECASE):
                    is_metadata = True
                    break
            
            if not is_metadata:
                cleaned_lines.append(stripped)
        
        return '\n'.join(cleaned_lines).strip()
    
    def detect_language(self, text: str) -> str:
        """åµæ¸¬æ–‡æœ¬ä¸»è¦èªè¨€"""
        # è¨ˆç®—ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        total_chars = len(re.findall(r'\w', text)) + chinese_chars
        
        if total_chars == 0:
            return 'unknown'
        
        chinese_ratio = chinese_chars / total_chars
        
        if chinese_ratio > 0.3:
            return 'zh'
        else:
            return 'en'
    
    def convert_to_traditional_tw(self, text: str) -> str:
        """
        ç°¡é«”ä¸­æ–‡ â†’ ç¹é«”ä¸­æ–‡ (å°ç£ç”¨è©)
        
        ä½¿ç”¨ OpenCC é€²è¡Œè½‰æ› (è‹¥å·²å®‰è£)
        å¦å‰‡ä½¿ç”¨åŸºæœ¬è©å½™æ›¿æ›è¡¨
        """
        try:
            import opencc
            converter = opencc.OpenCC('s2twp')  # ç°¡é«”åˆ°ç¹é«”ï¼ˆå°ç£ç”¨è©ï¼‰
            return converter.convert(text)
        except ImportError:
            # åŸºæœ¬è©å½™æ›¿æ›è¡¨ï¼ˆéƒ¨åˆ†å¸¸è¦‹ç”¨è©ï¼‰
            replacements = {
                'è§†é¢‘': 'å½±ç‰‡',
                'è½¯ä»¶': 'è»Ÿé«”',
                'ç¡¬ä»¶': 'ç¡¬é«”',
                'å†…å­˜': 'è¨˜æ†¶é«”',
                'ç¨‹åº': 'ç¨‹å¼',
                'ä¿¡æ¯': 'è³‡è¨Š',
                'æ•°æ®': 'è³‡æ–™',
                'ç½‘ç»œ': 'ç¶²è·¯',
                'äº‘ç«¯': 'é›²ç«¯',
                'ç”¨æˆ·': 'ä½¿ç”¨è€…',
                'æœåŠ¡å™¨': 'ä¼ºæœå™¨',
                'æ–‡ä»¶': 'æª”æ¡ˆ',
                'å­—èŠ‚': 'ä½å…ƒçµ„',
                'ç•Œé¢': 'ä»‹é¢',
                'ç³»ç»Ÿ': 'ç³»çµ±',
                'è´¨é‡': 'å“è³ª',
                'ä¼˜åŒ–': 'æœ€ä½³åŒ–',
                'æ–¹æ¡ˆ': 'æ–¹æ¡ˆ',  # ä¿æŒ
                'é¡¹ç›®': 'å°ˆæ¡ˆ',
                'å›¢é˜Ÿ': 'åœ˜éšŠ',
                'åˆ›ä¸š': 'å‰µæ¥­',
                'å•†ä¸š': 'å•†æ¥­',
                'è¥é”€': 'è¡ŒéŠ·',
                'å“ç‰Œ': 'å“ç‰Œ',  # ä¿æŒ
                'å®¢æˆ·': 'å®¢æˆ¶',
                'äº§å“': 'ç”¢å“',
                'æœåŠ¡': 'æœå‹™',
                'ç®¡ç†': 'ç®¡ç†',  # ä¿æŒ
                'æŠ€æœ¯': 'æŠ€è¡“',
                'å‘å±•': 'ç™¼å±•',
            }
            
            result = text
            for simp, trad in replacements.items():
                result = result.replace(simp, trad)
            
            return result
    
    def polish(self, transcript: str, use_llm: bool = True) -> str:
        """
        å®Œæ•´çš„é€å­—ç¨¿æ¢³ç†æµç¨‹
        
        Args:
            transcript: åŸå§‹é€å­—ç¨¿
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM é€²è¡Œæ·±åº¦æ¢³ç†
            
        Returns:
            æ¢³ç†å¾Œçš„é€å­—ç¨¿
        """
        if not transcript:
            return transcript
        
        # Step 1: æ¸…ç†å…ƒæ•¸æ“š
        cleaned = self.clean_metadata(transcript)
        
        if not cleaned:
            return transcript
        
        # Step 2: åµæ¸¬èªè¨€
        lang = self.detect_language(cleaned)
        
        # Step 3: LLM æ·±åº¦æ¢³ç† (å¯é¸)
        if use_llm and len(cleaned) > 100:
            try:
                polished = self.llm.generate(
                    prompt=f"{self.POLISHER_PROMPT}\n\n{cleaned[:12000]}",
                    system_prompt="ä½ æ˜¯å°ˆæ¥­é€å­—ç¨¿è™•ç†å°ˆå®¶ã€‚åš´æ ¼éµå®ˆè¦å‰‡ï¼Œç‰¹åˆ¥æ˜¯ä¿æŒåŸèªè¨€ã€‚",
                    max_tokens=8000,
                    temperature=0.2
                )
                if polished and len(polished) > len(cleaned) * 0.5:  # ç¢ºä¿è¼¸å‡ºåˆç†
                    cleaned = polished
            except Exception as e:
                print(f"âš ï¸ LLM æ¢³ç†å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹æ¸…ç†ç‰ˆæœ¬: {e}")
        
        # Step 4: ä¸­æ–‡å…§å®¹è½‰ç¹é«”+å°ç£ç”¨è©
        if lang == 'zh':
            cleaned = self.convert_to_traditional_tw(cleaned)
        
        return cleaned


# ä¾¿æ·å‡½æ•¸
def polish_transcript(transcript: str, use_llm: bool = True) -> str:
    """ä¾¿æ·å‡½æ•¸ï¼šæ¢³ç†é€å­—ç¨¿"""
    polisher = TranscriptPolisher()
    return polisher.polish(transcript, use_llm=use_llm)


if __name__ == "__main__":
    print("ğŸ“ TranscriptPolisher æ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦æ–‡æœ¬
    test_transcript = """Kind: captions
Language: zh-Hans

æˆ‘å¼€å§‹æ€è€ƒçš„ä¸€ä»¶äº‹æ˜¯
Cortex æœ‰ä»€ä¹ˆé—®é¢˜
æˆ‘ä»¬å¥½åƒå®Œå…¨æ— æ³•å‰è¿›
åªæ˜¯åŸåœ°è¸æ­¥
è¯„è®ºä¸æ–­æ¶Œå…¥
å…¶ä»–äº‹æƒ…ä¹Ÿæ¥è¸µè€Œæ¥
æˆ‘ä»¬åˆ°åº•åœ¨åšä»€ä¹ˆ"""
    
    polisher = TranscriptPolisher()
    
    # æ¸¬è©¦æ¸…ç†
    cleaned = polisher.clean_metadata(test_transcript)
    print("æ¸…ç†å¾Œ:")
    print(cleaned)
    print()
    
    # æ¸¬è©¦èªè¨€åµæ¸¬
    lang = polisher.detect_language(cleaned)
    print(f"åµæ¸¬èªè¨€: {lang}")
    print()
    
    # æ¸¬è©¦ç¹é«”è½‰æ›
    trad = polisher.convert_to_traditional_tw(cleaned)
    print("ç¹é«”è½‰æ›:")
    print(trad)
