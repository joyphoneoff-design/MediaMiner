#!/usr/bin/env python3
"""
çŸ¥è­˜æå–å™¨
å¾é€å­—ç¨¿ä¸­æå–å•†æ¥­çŸ¥è­˜
"""

import os
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime

# å°å…¥æœ¬åœ°æ¨¡çµ„
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from processors.llm_client import get_llm_client


class KnowledgeExtractor:
    """å•†æ¥­çŸ¥è­˜æå–å™¨"""
    
    def __init__(self, prompts_dir: str = None):
        if prompts_dir is None:
            prompts_dir = Path(__file__).parent.parent / "config" / "prompts"
        self.prompts_dir = Path(prompts_dir)
        self.llm = get_llm_client()
        
        # è¼‰å…¥ Prompts
        self.knowledge_prompt = self._load_prompt("knowledge_extraction.txt")
        self.speaker_prompt = self._load_prompt("speaker_identification.txt")
    
    def _load_prompt(self, filename: str) -> str:
        """è¼‰å…¥ Prompt æ¨¡æ¿"""
        prompt_file = self.prompts_dir / filename
        if prompt_file.exists():
            return prompt_file.read_text(encoding='utf-8')
        return ""
    
    def identify_speakers(self, transcript: str, video_info: Dict = None) -> str:
        """
        è­˜åˆ¥è¬›è€…ï¼ˆä½¿ç”¨å½±ç‰‡å…ƒæ•¸æ“šè¼”åŠ©è­˜åˆ¥ï¼‰
        
        Args:
            transcript: åŸå§‹é€å­—ç¨¿
            video_info: å½±ç‰‡è³‡è¨Š {'title', 'channel', 'description'}
            
        Returns:
            æ¨™è¨˜è¬›è€…å¾Œçš„é€å­—ç¨¿
        """
        # å¾å½±ç‰‡å…ƒæ•¸æ“šæå–è¬›è€…è³‡è¨Š
        speaker_hints = ""
        if video_info:
            channel = video_info.get('channel', '')
            title = video_info.get('title', '')
            description = video_info.get('description', '')[:500] if video_info.get('description') else ''
            
            speaker_hints = f"""
## å·²çŸ¥è¬›è€…è³‡è¨Šï¼ˆè«‹å„ªå…ˆä½¿ç”¨ï¼‰

- **é »é“ä¸»æŒäºº/ä¸»è¬›è€…**: {channel}
- **å½±ç‰‡æ¨™é¡Œ**: {title}
- **æè¿°æ‘˜è¦**: {description[:200] if description else 'ç„¡'}

### è­˜åˆ¥è¦å‰‡
1. è‹¥ç‚ºå–®äººå½±ç‰‡ï¼ˆVlogã€æ•™å­¸ï¼‰ï¼Œä¸»è¬›è€…ç‚ºé »é“æ“æœ‰è€…ã€Œ{channel}ã€
2. è‹¥ç‚ºè¨ªè«‡ï¼Œä¸»æŒäººé€šå¸¸æ˜¯é »é“æ“æœ‰è€…ã€Œ{channel}ã€
3. è¨ªè«‡å˜‰è³“å§“åå¯èƒ½å‡ºç¾åœ¨æ¨™é¡Œæˆ–æè¿°ä¸­
4. **ç¦æ­¢ä½¿ç”¨è™›æ§‹æˆ–ä½”ä½ç¬¦å§“å**ï¼ˆå¦‚ Cortexã€å¼µä¸‰ç­‰ï¼‰
5. ç„¡æ³•è­˜åˆ¥æ™‚ç”¨ã€Œä¸»è¬›è€…ã€æˆ–ã€Œå˜‰è³“ã€ä»£æ›¿
"""

        prompt = f"""
{self.speaker_prompt}

{speaker_hints}

## å¾…åˆ†æé€å­—ç¨¿

{transcript[:8000]}
"""
        
        result = self.llm.generate(
            prompt=prompt,
            system_prompt=f"ä½ æ˜¯å°ˆæ¥­çš„èªéŸ³åˆ†æå¸«ã€‚æ­¤å½±ç‰‡ä¾†è‡ªé »é“ã€Œ{video_info.get('channel', 'æœªçŸ¥')}ã€ï¼Œè«‹è­˜åˆ¥å°è©±ä¸­çš„ä¸åŒè¬›è€…ã€‚",
            max_tokens=8000,
            temperature=0.3
        )
        
        return result if result else transcript
    
    def extract_knowledge(self, transcript: str, video_info: Dict = None) -> Dict:
        """
        æå–å•†æ¥­çŸ¥è­˜ï¼ˆåˆä½µèª¿ç”¨ï¼šçŸ¥è­˜ + æ‘˜è¦ + é—œéµå­—ï¼‰
        
        Args:
            transcript: é€å­—ç¨¿ (å·²æ¨™è¨˜è¬›è€…)
            video_info: å½±ç‰‡è³‡è¨Š {'title': ..., 'url': ..., 'duration': ...}
            
        Returns:
            æå–çš„çŸ¥è­˜ {'summary': ..., 'knowledge': ..., 'keywords': ...}
        """
        # æ™ºèƒ½æˆªæ–·ï¼šç§»é™¤é‡è¤‡è¡Œ
        lines = transcript.split('\n')
        unique_lines = list(dict.fromkeys(lines))
        clean_transcript = '\n'.join([l for l in unique_lines if len(l.strip()) > 5])[:10000]
        
        # æº–å‚™ä¸Šä¸‹æ–‡
        context = ""
        if video_info:
            context = f"""
## å½±ç‰‡è³‡è¨Š
- æ¨™é¡Œ: {video_info.get('title', 'æœªçŸ¥')}
- ä¾†æº: {video_info.get('channel', 'æœªçŸ¥')}
- æ™‚é•·: {video_info.get('duration', 'æœªçŸ¥')}
"""
        
        # åˆä½µ Promptï¼šçŸ¥è­˜æå– + æ‘˜è¦ + é—œéµå­—
        prompt = f"""
{self.knowledge_prompt}

{context}

## é€å­—ç¨¿å…§å®¹

{clean_transcript}

---

## é¡å¤–è¼¸å‡ºï¼ˆè«‹åœ¨çŸ¥è­˜æå–å¾Œæ·»åŠ ï¼‰

### ä¸€å¥è©±æ‘˜è¦
è«‹åœ¨æ–‡æœ«æ·»åŠ ï¼š
`<!-- SUMMARY: [ä¸è¶…é100å­—çš„æ ¸å¿ƒè§€é»æ‘˜è¦] -->`

### é—œéµå­—
è«‹åœ¨æ–‡æœ«æ·»åŠ ï¼š
`<!-- KEYWORDS: ["é—œéµå­—1", "é—œéµå­—2", ...] -->`
"""
        
        result_text = self.llm.generate(
            prompt=prompt,
            system_prompt="ä½ æ˜¯å•†æ¥­çŸ¥è­˜æå–å°ˆå®¶ã€‚è«‹å¾é€å­—ç¨¿ä¸­æå–çŸ¥è­˜ï¼Œä¸¦åœ¨æ–‡æœ«æŒ‰æŒ‡å®šæ ¼å¼æ·»åŠ æ‘˜è¦å’Œé—œéµå­—ã€‚",
            max_tokens=4500,
            temperature=0.5
        )
        
        if not result_text:
            return {"error": "çŸ¥è­˜æå–å¤±æ•—"}
        
        # è§£æåˆä½µçµæœ
        summary = ""
        keywords = []
        knowledge = result_text
        
        # æå–æ‘˜è¦
        import re
        summary_match = re.search(r'<!-- SUMMARY: (.+?) -->', result_text)
        if summary_match:
            summary = summary_match.group(1).strip()
            knowledge = knowledge.replace(summary_match.group(0), '')
        
        # æå–é—œéµå­—
        keywords_match = re.search(r'<!-- KEYWORDS: (\[.+?\]) -->', result_text)
        if keywords_match:
            try:
                import json
                keywords = json.loads(keywords_match.group(1))
                knowledge = knowledge.replace(keywords_match.group(0), '')
            except:
                pass
        
        return {
            "knowledge": knowledge.strip(),
            "summary": summary,
            "keywords": keywords,
            "metadata": {
                "processed_at": datetime.now().isoformat(),
                "llm_provider": self.llm.current_provider,
                "video_info": video_info,
                "optimized": True  # æ¨™è¨˜ä½¿ç”¨å„ªåŒ–ç‰ˆæœ¬
            }
        }
    def _should_skip_speaker_id(self, video_info: Dict) -> bool:
        """
        åˆ¤æ–·æ˜¯å¦è·³éè¬›è€…è­˜åˆ¥ï¼ˆå„ªåŒ– API èª¿ç”¨ï¼‰
        
        è·³éæ¢ä»¶ï¼š
        - æ¨™é¡Œä¸åŒ…å«è¨ªè«‡ç›¸é—œè©å½™
        - éæ˜é¡¯å¤šäººå°è©±å…§å®¹
        """
        if not video_info:
            return False
        
        title = video_info.get('title', '').lower()
        
        # è¨ªè«‡ç›¸é—œé—œéµå­—ï¼ˆéœ€è¦è¬›è€…è­˜åˆ¥ï¼‰
        interview_keywords = [
            'è¨ªè«‡', 'å°ˆè¨ª', 'å°è«‡', 'å°è©±', 'interview', 'podcast', 
            'å˜‰è³“', 'guest', 'feat', 'ft.', 'ft', 'with', 'èˆ‡', 'å’Œ',
            'q&a', 'qa', 'å•ç­”'
        ]
        
        # å¦‚æœæ¨™é¡ŒåŒ…å«è¨ªè«‡é—œéµå­—ï¼Œä¸è·³é
        for keyword in interview_keywords:
            if keyword in title:
                return False
        
        # å–®äººå…§å®¹é—œéµå­—ï¼ˆå¯è·³éè¬›è€…è­˜åˆ¥ï¼‰
        solo_keywords = [
            'vlog', 'æ•™å­¸', 'tutorial', 'guide', 'åˆ†äº«', 'å¿ƒå¾—',
            'review', 'è©•æ¸¬', 'é–‹ç®±', 'unbox', 'æ—¥å¸¸', 'routine'
        ]
        
        for keyword in solo_keywords:
            if keyword in title:
                return True
        
        # é è¨­ï¼šä¸è·³éï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        return False
    
    def process_transcript(self, transcript: str, video_info: Dict = None) -> Dict:
        """
        å®Œæ•´è™•ç†é€å­—ç¨¿ï¼ˆå„ªåŒ–ç‰ˆï¼‰
        
        Args:
            transcript: åŸå§‹é€å­—ç¨¿
            video_info: å½±ç‰‡è³‡è¨Š
            
        Returns:
            è™•ç†çµæœ
        """
        print("ğŸ” é–‹å§‹è™•ç†é€å­—ç¨¿...")
        
        # 1. æ™ºèƒ½åˆ¤æ–·æ˜¯å¦éœ€è¦è¬›è€…è­˜åˆ¥
        if self._should_skip_speaker_id(video_info):
            print("   âš¡ è·³éè¬›è€…è­˜åˆ¥ï¼ˆå–®äººå…§å®¹ï¼‰")
            marked_transcript = transcript
        else:
            print("   ğŸ‘¥ è­˜åˆ¥è¬›è€…...")
            marked_transcript = self.identify_speakers(transcript, video_info)
        
        # 2. æå–çŸ¥è­˜ï¼ˆå·²åˆä½µæ‘˜è¦å’Œé—œéµå­—ï¼‰
        print("   ğŸ“š æå–å•†æ¥­çŸ¥è­˜...")
        result = self.extract_knowledge(marked_transcript, video_info)
        
        # 3. æ·»åŠ æ¨™è¨˜å¾Œçš„é€å­—ç¨¿
        result["marked_transcript"] = marked_transcript
        
        print("âœ… è™•ç†å®Œæˆ!")
        return result


if __name__ == "__main__":
    print("ğŸ§  MediaMiner Knowledge Extractor")
    print("=" * 50)
    
    extractor = KnowledgeExtractor()
    
    # æ¸¬è©¦æ–‡æœ¬
    test_transcript = """
    ä¸»æŒäººï¼šå¤§å®¶å¥½ï¼Œæ­¡è¿ä¾†åˆ°ä»Šå¤©çš„ç¯€ç›®ã€‚ä»Šå¤©æˆ‘å€‘é‚€è«‹åˆ°äº†çŸ¥åå‰µæ¥­è€…å¼µå…ˆç”Ÿã€‚
    å¼µå…ˆç”Ÿï¼šè¬è¬é‚€è«‹ã€‚
    ä¸»æŒäººï¼šæ‚¨èƒ½è·Ÿæˆ‘å€‘åˆ†äº«ä¸€ä¸‹å‰µæ¥­åˆæœŸæœ€é‡è¦çš„æ˜¯ä»€éº¼å—ï¼Ÿ
    å¼µå…ˆç”Ÿï¼šæˆ‘èªç‚ºæœ€é‡è¦çš„æ˜¯æ‰¾åˆ°ç”¢å“å¸‚å ´åŒ¹é…ã€‚å¾ˆå¤šå‰µæ¥­è€…ä¸€é–‹å§‹å°±æƒ³è‘—æ“´å¼µï¼Œ
    ä½†å…¶å¯¦æ‡‰è©²å…ˆé©—è­‰ä½ çš„ç”¢å“æ˜¯å¦çœŸæ­£è§£æ±ºäº†ç”¨æˆ¶çš„ç—›é»ã€‚
    """
    
    result = extractor.process_transcript(
        test_transcript,
        {"title": "å‰µæ¥­è¨ªè«‡", "channel": "æ¸¬è©¦é »é“"}
    )
    
    print("\nğŸ“Š çµæœ:")
    print(f"æ‘˜è¦: {result.get('summary', 'N/A')}")
    print(f"é—œéµå­—: {result.get('keywords', [])}")
