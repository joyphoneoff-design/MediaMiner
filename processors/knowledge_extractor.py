#!/usr/bin/env python3
"""
çŸ¥è­˜æå–å™¨
å¾é€å­—ç¨¿ä¸­æå–å•†æ¥­çŸ¥è­˜
"""

import os
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime

# å°å…¥æœ¬åœ°æ¨¡çµ„
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from processors.llm_client import get_llm_client


class KnowledgeExtractor:
    """å•†æ¥­çŸ¥è­˜æå–å™¨"""
    
    def __init__(self, prompts_dir: str = None):
        if prompts_dir is None:
            prompts_dir = Path(__file__).parent.parent / "config" / "prompts"
        self.prompts_dir = Path(prompts_dir)
        self.llm = get_llm_client()
        
        # è¼‰å…¥ Prompts
        self.knowledge_prompt = self._load_prompt("knowledge_extraction.txt")
        self.speaker_prompt = self._load_prompt("speaker_identification.txt")
    
    def _load_prompt(self, filename: str) -> str:
        """è¼‰å…¥ Prompt æ¨¡æ¿"""
        prompt_file = self.prompts_dir / filename
        if prompt_file.exists():
            return prompt_file.read_text(encoding='utf-8')
        return ""
    
    def identify_speakers(self, transcript: str) -> str:
        """
        è­˜åˆ¥è¬›è€…
        
        Args:
            transcript: åŸå§‹é€å­—ç¨¿
            
        Returns:
            æ¨™è¨˜è¬›è€…å¾Œçš„é€å­—ç¨¿
        """
        prompt = f"""
{self.speaker_prompt}

## å¾…åˆ†æé€å­—ç¨¿

{transcript[:8000]}  # é™åˆ¶é•·åº¦é¿å…è¶…å‡º token
"""
        
        result = self.llm.generate(
            prompt=prompt,
            system_prompt="ä½ æ˜¯å°ˆæ¥­çš„èªéŸ³åˆ†æå¸«ï¼Œè«‹è­˜åˆ¥å°è©±ä¸­çš„ä¸åŒè¬›è€…ã€‚",
            max_tokens=8000,
            temperature=0.3
        )
        
        return result if result else transcript
    
    def extract_knowledge(self, transcript: str, video_info: Dict = None) -> Dict:
        """
        æå–å•†æ¥­çŸ¥è­˜
        
        Args:
            transcript: é€å­—ç¨¿ (å·²æ¨™è¨˜è¬›è€…)
            video_info: å½±ç‰‡è³‡è¨Š {'title': ..., 'url': ..., 'duration': ...}
            
        Returns:
            æå–çš„çŸ¥è­˜ {'summary': ..., 'knowledge': ..., 'metadata': ...}
        """
        # æº–å‚™ä¸Šä¸‹æ–‡
        context = ""
        if video_info:
            context = f"""
## å½±ç‰‡è³‡è¨Š
- æ¨™é¡Œ: {video_info.get('title', 'æœªçŸ¥')}
- ä¾†æº: {video_info.get('channel', 'æœªçŸ¥')}
- æ™‚é•·: {video_info.get('duration', 'æœªçŸ¥')}
"""
        
        prompt = f"""
{self.knowledge_prompt}

{context}

## é€å­—ç¨¿å…§å®¹

{transcript[:12000]}  # é™åˆ¶é•·åº¦
"""
        
        knowledge_text = self.llm.generate(
            prompt=prompt,
            system_prompt="ä½ æ˜¯å•†æ¥­çŸ¥è­˜æå–å°ˆå®¶ï¼Œè«‹å¾é€å­—ç¨¿ä¸­æå–é—œéµå•†æ¥­çŸ¥è­˜ã€‚",
            max_tokens=4000,
            temperature=0.5
        )
        
        if not knowledge_text:
            return {"error": "çŸ¥è­˜æå–å¤±æ•—"}
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self._generate_summary(transcript[:4000])
        
        # æå–é—œéµå­—
        keywords = self._extract_keywords(transcript[:4000])
        
        return {
            "knowledge": knowledge_text,
            "summary": summary,
            "keywords": keywords,
            "metadata": {
                "processed_at": datetime.now().isoformat(),
                "llm_provider": self.llm.current_provider,
                "video_info": video_info
            }
        }
    
    def _generate_summary(self, text: str) -> str:
        """ç”Ÿæˆä¸€å¥è©±æ‘˜è¦"""
        prompt = f"""
è«‹ç”¨ä¸€å¥è©±ï¼ˆä¸è¶…é100å­—ï¼‰ç¸½çµä»¥ä¸‹å…§å®¹çš„æ ¸å¿ƒè§€é»ï¼š

{text}
"""
        result = self.llm.generate(
            prompt=prompt,
            system_prompt="è«‹ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡ºç°¡æ½”çš„æ‘˜è¦ã€‚",
            max_tokens=200,
            temperature=0.3
        )
        return result if result else ""
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–é—œéµå­—"""
        prompt = f"""
è«‹å¾ä»¥ä¸‹å…§å®¹ä¸­æå– 5-10 å€‹é—œéµå­—ï¼Œä»¥ JSON æ•¸çµ„æ ¼å¼è¼¸å‡ºï¼š

{text}

è¼¸å‡ºæ ¼å¼: ["é—œéµå­—1", "é—œéµå­—2", ...]
"""
        result = self.llm.generate(
            prompt=prompt,
            system_prompt="è«‹è¼¸å‡ºç´” JSON æ•¸çµ„ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚",
            max_tokens=200,
            temperature=0.3
        )
        
        if result:
            try:
                import json
                # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç¢¼å¡Š
                result = result.strip().strip('`').strip()
                if result.startswith('json'):
                    result = result[4:].strip()
                return json.loads(result)
            except:
                pass
        
        return []
    
    def process_transcript(self, transcript: str, video_info: Dict = None) -> Dict:
        """
        å®Œæ•´è™•ç†é€å­—ç¨¿
        
        Args:
            transcript: åŸå§‹é€å­—ç¨¿
            video_info: å½±ç‰‡è³‡è¨Š
            
        Returns:
            è™•ç†çµæœ
        """
        print("ğŸ” é–‹å§‹è™•ç†é€å­—ç¨¿...")
        
        # 1. è­˜åˆ¥è¬›è€…
        print("   ğŸ‘¥ è­˜åˆ¥è¬›è€…...")
        marked_transcript = self.identify_speakers(transcript)
        
        # 2. æå–çŸ¥è­˜
        print("   ğŸ“š æå–å•†æ¥­çŸ¥è­˜...")
        result = self.extract_knowledge(marked_transcript, video_info)
        
        # 3. æ·»åŠ æ¨™è¨˜å¾Œçš„é€å­—ç¨¿
        result["marked_transcript"] = marked_transcript
        
        print("âœ… è™•ç†å®Œæˆ!")
        return result


if __name__ == "__main__":
    print("ğŸ§  MediaMiner Knowledge Extractor")
    print("=" * 50)
    
    extractor = KnowledgeExtractor()
    
    # æ¸¬è©¦æ–‡æœ¬
    test_transcript = """
    ä¸»æŒäººï¼šå¤§å®¶å¥½ï¼Œæ­¡è¿ä¾†åˆ°ä»Šå¤©çš„ç¯€ç›®ã€‚ä»Šå¤©æˆ‘å€‘é‚€è«‹åˆ°äº†çŸ¥åå‰µæ¥­è€…å¼µå…ˆç”Ÿã€‚
    å¼µå…ˆç”Ÿï¼šè¬è¬é‚€è«‹ã€‚
    ä¸»æŒäººï¼šæ‚¨èƒ½è·Ÿæˆ‘å€‘åˆ†äº«ä¸€ä¸‹å‰µæ¥­åˆæœŸæœ€é‡è¦çš„æ˜¯ä»€éº¼å—ï¼Ÿ
    å¼µå…ˆç”Ÿï¼šæˆ‘èªç‚ºæœ€é‡è¦çš„æ˜¯æ‰¾åˆ°ç”¢å“å¸‚å ´åŒ¹é…ã€‚å¾ˆå¤šå‰µæ¥­è€…ä¸€é–‹å§‹å°±æƒ³è‘—æ“´å¼µï¼Œ
    ä½†å…¶å¯¦æ‡‰è©²å…ˆé©—è­‰ä½ çš„ç”¢å“æ˜¯å¦çœŸæ­£è§£æ±ºäº†ç”¨æˆ¶çš„ç—›é»ã€‚
    """
    
    result = extractor.process_transcript(
        test_transcript,
        {"title": "å‰µæ¥­è¨ªè«‡", "channel": "æ¸¬è©¦é »é“"}
    )
    
    print("\nğŸ“Š çµæœ:")
    print(f"æ‘˜è¦: {result.get('summary', 'N/A')}")
    print(f"é—œéµå­—: {result.get('keywords', [])}")
