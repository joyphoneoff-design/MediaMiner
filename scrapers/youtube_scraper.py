#!/usr/bin/env python3
"""
YouTube é »é“çˆ¬èŸ²
æ‰¹æ¬¡åˆ—èˆ‰é »é“æ‰€æœ‰å½±ç‰‡ä¸¦ä¸‹è¼‰å­—å¹•
"""

import os
import json
import subprocess
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime
import re

class YouTubeScraper:
    """YouTube é »é“çˆ¬èŸ²é¡"""
    
    def __init__(self, output_dir: str = "~/Documents/Crawl_R2R_Data/raw"):
        self.output_dir = Path(output_dir).expanduser()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def get_channel_videos(self, channel_url: str, max_videos: int = 100) -> List[Dict]:
        """
        åˆ—èˆ‰é »é“æ‰€æœ‰å½±ç‰‡
        
        Args:
            channel_url: YouTube é »é“ URL
            max_videos: æœ€å¤§å½±ç‰‡æ•¸é‡
            
        Returns:
            å½±ç‰‡åˆ—è¡¨ [{'id': ..., 'title': ..., 'url': ...}, ...]
        """
        cmd = [
            "yt-dlp",
            "--flat-playlist",
            "--dump-json",
            "--playlist-end", str(max_videos),
            channel_url
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            videos = []
            for line in result.stdout.strip().split('\n'):
                if line:
                    video = json.loads(line)
                    videos.append({
                        'id': video.get('id'),
                        'title': video.get('title'),
                        'url': f"https://www.youtube.com/watch?v={video.get('id')}",
                        'duration': video.get('duration'),
                        'upload_date': video.get('upload_date')
                    })
            return videos
        except subprocess.CalledProcessError as e:
            print(f"Error getting channel videos: {e.stderr}")
            return []
    
    def download_subtitles(self, video_url: str, langs: List[str] = None) -> Optional[str]:
        """
        ä¸‹è¼‰å½±ç‰‡å­—å¹•
        
        Args:
            video_url: å½±ç‰‡ URL
            langs: å­—å¹•èªè¨€å„ªå…ˆé †åº
            
        Returns:
            å­—å¹•æª”æ¡ˆè·¯å¾‘
        """
        if langs is None:
            langs = ["zh-TW", "zh-CN", "zh", "en"]
        
        # å…ˆå˜—è©¦æ‰‹å‹•å­—å¹•ï¼Œå†å˜—è©¦è‡ªå‹•å­—å¹•
        for auto in [False, True]:
            cmd = [
                "yt-dlp",
                "--skip-download",
                "--write-sub" if not auto else "--write-auto-sub",
                "--sub-langs", ",".join(langs),
                "--sub-format", "vtt",
                "--convert-subs", "srt",
                "-o", str(self.output_dir / "%(title)s.%(ext)s"),
                video_url
            ]
            
            try:
                result = subprocess.run(cmd, capture_output=True, text=True)
                # æŸ¥æ‰¾ç”Ÿæˆçš„å­—å¹•æª”æ¡ˆ
                for f in self.output_dir.glob("*.srt"):
                    if f.stat().st_mtime > datetime.now().timestamp() - 60:
                        return str(f)
            except subprocess.CalledProcessError:
                continue
        
        return None
    
    def batch_download_subtitles(self, channel_url: str, max_videos: int = 50) -> List[Dict]:
        """
        æ‰¹æ¬¡ä¸‹è¼‰é »é“å½±ç‰‡å­—å¹•
        
        Args:
            channel_url: é »é“ URL
            max_videos: æœ€å¤§å½±ç‰‡æ•¸
            
        Returns:
            ä¸‹è¼‰çµæœåˆ—è¡¨
        """
        print(f"ğŸ“º æ­£åœ¨ç²å–é »é“å½±ç‰‡åˆ—è¡¨...")
        videos = self.get_channel_videos(channel_url, max_videos)
        print(f"âœ… æ‰¾åˆ° {len(videos)} éƒ¨å½±ç‰‡")
        
        results = []
        for i, video in enumerate(videos, 1):
            print(f"â¬‡ï¸  [{i}/{len(videos)}] ä¸‹è¼‰å­—å¹•: {video['title'][:50]}...")
            
            subtitle_path = self.download_subtitles(video['url'])
            
            results.append({
                'video': video,
                'subtitle_path': subtitle_path,
                'success': subtitle_path is not None
            })
            
            if subtitle_path:
                print(f"   âœ… æˆåŠŸ: {subtitle_path}")
            else:
                print(f"   âš ï¸  æœªæ‰¾åˆ°å­—å¹•ï¼Œç¨å¾Œå°‡ä½¿ç”¨ Whisper")
        
        success_count = sum(1 for r in results if r['success'])
        print(f"\nğŸ“Š å®Œæˆ! æˆåŠŸä¸‹è¼‰ {success_count}/{len(videos)} éƒ¨å½±ç‰‡å­—å¹•")
        
        return results


def clean_vtt_to_text(vtt_content: str) -> str:
    """
    æ¸…ç† VTT/SRT å­—å¹•ç‚ºç´”æ–‡å­—
    
    Args:
        vtt_content: VTT/SRT å…§å®¹
        
    Returns:
        ç´”æ–‡å­—å…§å®¹
    """
    # ç§»é™¤ VTT é ­éƒ¨
    lines = vtt_content.split('\n')
    text_lines = []
    
    for line in lines:
        line = line.strip()
        # è·³éæ™‚é–“è»¸
        if re.match(r'^\d{2}:\d{2}:\d{2}', line):
            continue
        # è·³éåºè™Ÿ
        if re.match(r'^\d+$', line):
            continue
        # è·³éç©ºè¡Œå’Œ WEBVTT æ¨™è¨˜
        if not line or line.startswith('WEBVTT') or line.startswith('NOTE'):
            continue
        # ç§»é™¤ HTML æ¨™ç±¤
        line = re.sub(r'<[^>]+>', '', line)
        if line:
            text_lines.append(line)
    
    # åˆä½µé‡è¤‡è¡Œ
    unique_lines = []
    prev_line = ""
    for line in text_lines:
        if line != prev_line:
            unique_lines.append(line)
            prev_line = line
    
    return '\n'.join(unique_lines)


if __name__ == "__main__":
    # æ¸¬è©¦
    scraper = YouTubeScraper()
    
    # æ¸¬è©¦é »é“
    test_channel = "https://youtube.com/@dankoetalks"
    
    print("ğŸš€ Crawl_R2R YouTube Scraper")
    print("=" * 50)
    
    # ç²å–å½±ç‰‡åˆ—è¡¨ (å…ˆæ¸¬è©¦ 5 éƒ¨)
    videos = scraper.get_channel_videos(test_channel, max_videos=5)
    
    for v in videos:
        print(f"ğŸ“¹ {v['title'][:60]}...")
        print(f"   URL: {v['url']}")
        print()
