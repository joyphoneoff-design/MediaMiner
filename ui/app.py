#!/usr/bin/env python3
"""
MediaMiner Streamlit UI
ç¤¾äº¤åª’é«”çŸ¥è­˜æå–ç³»çµ±ä»‹é¢
"""

import os
import sys
from pathlib import Path
from datetime import datetime

import streamlit as st

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from scrapers.youtube_scraper import YouTubeScraper
from scrapers.transcript_fetcher import TranscriptFetcher
from processors.knowledge_extractor import KnowledgeExtractor
from processors.metadata_injector import MetadataInjector
from integrations.r2r_connector import R2RConnector

# ===========================================
# é é¢é…ç½®
# ===========================================
st.set_page_config(
    page_title="MediaMiner - å‰µæ¥­è€…çŸ¥è­˜åº«",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===========================================
# è‡ªå®šç¾©æ¨£å¼
# ===========================================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        color: #666;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    .stat-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius: 10px;
        padding: 1.5rem;
        text-align: center;
    }
    .stat-number {
        font-size: 2rem;
        font-weight: 700;
        color: #667eea;
    }
    .success-box {
        background: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background: #fff3cd;
        border: 1px solid #ffc107;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ===========================================
# Session State åˆå§‹åŒ–
# ===========================================
if 'videos' not in st.session_state:
    st.session_state.videos = []
if 'processed_count' not in st.session_state:
    st.session_state.processed_count = 0
if 'processing' not in st.session_state:
    st.session_state.processing = False

# ===========================================
# å´é‚Šæ¬„
# ===========================================
with st.sidebar:
    st.markdown("### ğŸ¯ MediaMiner")
    st.markdown("**ç¤¾äº¤åª’é«”çŸ¥è­˜æå–ç³»çµ±**")
    
    st.divider()
    
    # å°èˆª
    page = st.radio(
        "åŠŸèƒ½é¸æ“‡",
        ["ğŸ“º é »é“æ“·å–", "ğŸ“Š è™•ç†ç‹€æ…‹", "ğŸ” çŸ¥è­˜å•ç­”", "âš™ï¸ è¨­å®š"],
        label_visibility="collapsed"
    )
    
    st.divider()
    
    # ç‹€æ…‹å¡ç‰‡
    st.markdown("### ğŸ“ˆ çµ±è¨ˆ")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("å·²è™•ç†", st.session_state.processed_count)
    with col2:
        # è¨ˆç®—å·²è™•ç†æª”æ¡ˆæ•¸
        processed_dir = Path.home() / "Documents" / "MediaMiner_Data" / "processed"
        if processed_dir.exists():
            file_count = len(list(processed_dir.glob("*.md")))
        else:
            file_count = 0
        st.metric("æª”æ¡ˆæ•¸", file_count)
    
    st.divider()
    
    # R2R ç‹€æ…‹
    r2r = R2RConnector()
    status = r2r.check_r2r_status()
    if status.get('running'):
        st.success("âœ… R2R é‹è¡Œä¸­")
    else:
        st.warning("âš ï¸ R2R æœªé‹è¡Œ")

# ===========================================
# ä¸»å…§å®¹å€
# ===========================================

# é é¢æ¨™é¡Œ
st.markdown('<h1 class="main-header">ğŸ¯ MediaMiner</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">ä¸€äººå…¬å¸å‰µæ¥­è€…çŸ¥è­˜æå–æ¡†æ¶</p>', unsafe_allow_html=True)

# é »é“æ“·å–é é¢
if page == "ğŸ“º é »é“æ“·å–":
    st.markdown("## ğŸ“º é »é“æ“·å–")
    
    # è¼¸å…¥å€
    col1, col2 = st.columns([3, 1])
    
    with col1:
        channel_url = st.text_input(
            "YouTube é »é“ URL",
            placeholder="https://youtube.com/@dankoetalks",
            help="è¼¸å…¥ YouTube é »é“ URL"
        )
    
    with col2:
        max_videos = st.number_input("å½±ç‰‡æ•¸é‡", min_value=1, max_value=100, value=10)
    
    # é è¨­é »é“
    st.markdown("#### ğŸ”– é è¨­é »é“")
    preset_channels = [
        ("Dan Koe (YouTube)", "https://youtube.com/@dankoetalks"),
    ]
    
    col1, col2 = st.columns(2)
    for i, (name, url) in enumerate(preset_channels):
        with [col1, col2][i % 2]:
            if st.button(f"ğŸ“Œ {name}", key=f"preset_{i}"):
                channel_url = url
    
    with st.expander("âš ï¸ å°ç´…æ›¸é™åˆ¶èªªæ˜"):
        st.markdown("""
        å°ç´…æ›¸æœ‰åçˆ¬æ©Ÿåˆ¶ï¼Œç›®å‰æ”¯æ´æœ‰é™ï¼š
        - âŒ ç”¨æˆ¶ä¸»é é€£çµç„¡æ³•ç›´æ¥çˆ¬å–
        - âš ï¸ éœ€è¦å…·é«”ç­†è¨˜é€£çµ (`/explore/xxx`)
        - ğŸ’¡ å»ºè­°ï¼šæ‰‹å‹•è¤‡è£½ç­†è¨˜é€£çµ
        """)
    
    st.divider()
    
    # è™•ç†æŒ‰éˆ•
    if st.button("ğŸš€ é–‹å§‹æ“·å–", type="primary", disabled=st.session_state.processing):
        if channel_url:
            st.session_state.processing = True
            
            progress_bar = st.progress(0, text="åˆå§‹åŒ–...")
            status_container = st.empty()
            
            try:
                # åˆå§‹åŒ–å…ƒä»¶
                scraper = YouTubeScraper()
                fetcher = TranscriptFetcher()
                extractor = KnowledgeExtractor()
                injector = MetadataInjector()
                
                # 1. ç²å–å½±ç‰‡åˆ—è¡¨
                progress_bar.progress(10, text="ç²å–å½±ç‰‡åˆ—è¡¨...")
                videos = scraper.get_channel_videos(channel_url, max_videos)
                
                if not videos:
                    st.error("âŒ ç„¡æ³•ç²å–å½±ç‰‡åˆ—è¡¨")
                    st.session_state.processing = False
                else:
                    st.session_state.videos = videos
                    status_container.info(f"ğŸ“¹ æ‰¾åˆ° {len(videos)} éƒ¨å½±ç‰‡")
                    
                    # 2. è™•ç†æ¯éƒ¨å½±ç‰‡
                    results = []
                    for i, video in enumerate(videos):
                        progress = int(10 + (i / len(videos)) * 80)
                        progress_bar.progress(progress, text=f"è™•ç†: {video['title'][:40]}...")
                        
                        # ç²å–é€å­—ç¨¿
                        transcript = fetcher.fetch(video['url'])
                        
                        if transcript:
                            # æå–çŸ¥è­˜
                            knowledge = extractor.process_transcript(
                                transcript['text'],
                                video_info={
                                    'title': video['title'],
                                    'channel': channel_url,
                                    'duration': video.get('duration')
                                }
                            )
                            
                            # ç”Ÿæˆ MD æª”æ¡ˆ (ç´” MDï¼Œç„¡ YAML frontmatter)
                            md_content = injector.create_markdown(
                                content=transcript['text'],
                                knowledge=knowledge.get('knowledge', ''),
                                video_info={
                                    'title': video['title'],
                                    'source': channel_url,
                                    'platform': 'youtube',
                                    'url': video['url'],
                                    'duration': video.get('duration')
                                }
                            )
                            
                            # ä¿å­˜æª”æ¡ˆ
                            output_dir = Path.home() / "Documents" / "MediaMiner_Data" / "processed"
                            output_dir.mkdir(parents=True, exist_ok=True)
                            
                            filename = injector.generate_safe_filename(video['title'])
                            output_file = output_dir / f"{filename}.md"
                            output_file.write_text(md_content, encoding='utf-8')
                            
                            results.append({
                                'video': video,
                                'success': True,
                                'file': str(output_file)
                            })
                            st.session_state.processed_count += 1
                        else:
                            results.append({
                                'video': video,
                                'success': False,
                                'error': 'ç„¡æ³•ç²å–é€å­—ç¨¿'
                            })
                    
                    progress_bar.progress(100, text="å®Œæˆ!")
                    
                    # é¡¯ç¤ºçµæœ
                    success_count = sum(1 for r in results if r['success'])
                    st.success(f"âœ… å®Œæˆ! æˆåŠŸè™•ç† {success_count}/{len(videos)} éƒ¨å½±ç‰‡")
                    
                    # çµæœè¡¨æ ¼
                    with st.expander("ğŸ“‹ è™•ç†çµæœ"):
                        for r in results:
                            if r['success']:
                                st.markdown(f"âœ… **{r['video']['title'][:50]}...**")
                            else:
                                st.markdown(f"âŒ **{r['video']['title'][:50]}...** - {r.get('error', '')}")
                    
            except Exception as e:
                st.error(f"âŒ éŒ¯èª¤: {str(e)}")
            finally:
                st.session_state.processing = False
        else:
            st.warning("âš ï¸ è«‹è¼¸å…¥é »é“ URL")

# è™•ç†ç‹€æ…‹é é¢
elif page == "ğŸ“Š è™•ç†ç‹€æ…‹":
    st.markdown("## ğŸ“Š è™•ç†ç‹€æ…‹")
    
    # ç›®éŒ„çµ±è¨ˆ
    data_dir = Path.home() / "Documents" / "MediaMiner_Data"
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        raw_count = len(list((data_dir / "raw").glob("*"))) if (data_dir / "raw").exists() else 0
        st.metric("ğŸ“¥ åŸå§‹æª”æ¡ˆ", raw_count)
    
    with col2:
        processed_count = len(list((data_dir / "processed").glob("*.md"))) if (data_dir / "processed").exists() else 0
        st.metric("âœ… å·²è™•ç†", processed_count)
    
    with col3:
        knowledge_count = len(list((data_dir / "knowledge").glob("*.md"))) if (data_dir / "knowledge").exists() else 0
        st.metric("ğŸ“š çŸ¥è­˜å¡ç‰‡", knowledge_count)
    
    st.divider()
    
    # æœ€è¿‘è™•ç†çš„æª”æ¡ˆ
    st.markdown("### ğŸ“„ æœ€è¿‘è™•ç†çš„æª”æ¡ˆ")
    
    processed_dir = data_dir / "processed"
    if processed_dir.exists():
        files = sorted(processed_dir.glob("*.md"), key=lambda x: x.stat().st_mtime, reverse=True)[:10]
        
        for f in files:
            mtime = datetime.fromtimestamp(f.stat().st_mtime).strftime("%Y-%m-%d %H:%M")
            with st.expander(f"ğŸ“„ {f.name} ({mtime})"):
                content = f.read_text(encoding='utf-8')
                st.markdown(content[:2000] + "..." if len(content) > 2000 else content)
    else:
        st.info("ğŸ“­ é‚„æ²’æœ‰è™•ç†éçš„æª”æ¡ˆ")

# çŸ¥è­˜å•ç­”é é¢
elif page == "ğŸ” çŸ¥è­˜å•ç­”":
    st.markdown("## ğŸ” çŸ¥è­˜å•ç­”")
    
    # å•ç­”è¼¸å…¥
    query = st.text_input(
        "è¼¸å…¥æ‚¨çš„å•é¡Œ",
        placeholder="ä¾‹å¦‚ï¼šä»€éº¼æ˜¯å•†æ¥­æ¨¡å¼ç•«å¸ƒï¼Ÿå¦‚ä½•å»ºç«‹å€‹äººå“ç‰Œï¼Ÿ"
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ” æœ¬åœ°æœç´¢", type="primary"):
            if query:
                with st.spinner("æœç´¢ä¸­..."):
                    # æœ¬åœ°æª”æ¡ˆæœç´¢
                    knowledge_dir = Path.home() / "Documents" / "MediaMiner_Data" / "knowledge"
                    results = []
                    
                    if knowledge_dir.exists():
                        for f in knowledge_dir.glob("*.md"):
                            content = f.read_text(encoding='utf-8')
                            if query.lower() in content.lower():
                                results.append({
                                    'file': f.name,
                                    'content': content[:1000]
                                })
                    
                    if results:
                        st.markdown("### ğŸ“‹ æœç´¢çµæœ")
                        for r in results:
                            with st.expander(f"ğŸ“„ {r['file']}"):
                                st.markdown(r['content'])
                    else:
                        st.info("æœªæ‰¾åˆ°ç›¸é—œå…§å®¹")
    
    with col2:
        if st.button("ğŸ§  AI å•ç­”"):
            if query:
                with st.spinner("AI æ€è€ƒä¸­..."):
                    # ä½¿ç”¨ LLM ç›´æ¥å›ç­”
                    try:
                        from processors.llm_client import get_llm_client
                        
                        # è®€å–æ‰€æœ‰çŸ¥è­˜å¡ç‰‡ä½œç‚ºä¸Šä¸‹æ–‡
                        knowledge_dir = Path.home() / "Documents" / "MediaMiner_Data" / "knowledge"
                        context = ""
                        if knowledge_dir.exists():
                            for f in list(knowledge_dir.glob("*.md"))[:5]:
                                context += f.read_text(encoding='utf-8')[:2000] + "\n\n"
                        
                        client = get_llm_client()
                        prompt = f"""
åŸºæ–¼ä»¥ä¸‹çŸ¥è­˜åº«å…§å®¹å›ç­”å•é¡Œï¼š

{context[:6000]}

å•é¡Œï¼š{query}

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
"""
                        answer = client.generate(
                            prompt=prompt,
                            system_prompt="ä½ æ˜¯ä¸€ä½å•†æ¥­çŸ¥è­˜å°ˆå®¶ï¼Œè«‹æ ¹æ“šæä¾›çš„çŸ¥è­˜å…§å®¹å›ç­”å•é¡Œã€‚",
                            max_tokens=1000
                        )
                        
                        if answer:
                            st.markdown("### ğŸ’¡ AI å›ç­”")
                            st.markdown(answer)
                        else:
                            st.error("ç„¡æ³•ç²å–å›ç­”")
                    except Exception as e:
                        st.error(f"éŒ¯èª¤: {str(e)}")
    
    # R2R ç‹€æ…‹æç¤º
    with st.expander("â„¹ï¸ é—œæ–¼ R2R"):
        st.markdown("""
        **R2R å‘é‡æœç´¢** ç›®å‰æœªå•Ÿç”¨
        
        - æœ¬åœ°æœç´¢ï¼šåŸºæ–¼é—œéµå­—åŒ¹é…
        - AI å•ç­”ï¼šä½¿ç”¨ LLM ç›´æ¥åˆ†æçŸ¥è­˜å¡ç‰‡
        - RAG æœç´¢ï¼šéœ€è¦å•Ÿå‹• R2R æœå‹™
        """)

# è¨­å®šé é¢
elif page == "âš™ï¸ è¨­å®š":
    st.markdown("## âš™ï¸ è¨­å®š")
    
    # API å¯†é‘°è¨­å®š
    st.markdown("### ğŸ”‘ API å¯†é‘°")
    
    with st.expander("Gemini API"):
        gemini_key = st.text_input("Gemini API Key", type="password", 
                                    value=os.getenv("GEMINI_API_KEY", ""))
        gemini_key_backup = st.text_input("Gemini Backup Key", type="password",
                                           value=os.getenv("GEMINI_API_KEY_BACKUP", ""))
    
    with st.expander("Cerebras API"):
        cerebras_key = st.text_input("Cerebras API Key", type="password",
                                      value=os.getenv("CEREBRAS_API_KEY", ""))
    
    with st.expander("OpenAI API"):
        openai_key = st.text_input("OpenAI API Key", type="password",
                                    value=os.getenv("OPENAI_API_KEY", ""))
    
    st.divider()
    
    # R2R è¨­å®š
    st.markdown("### ğŸ—„ï¸ R2R é…ç½®")
    
    r2r = R2RConnector()
    status = r2r.check_r2r_status()
    
    col1, col2 = st.columns(2)
    with col1:
        st.text_input("Collection Name", value="crawl_r2r_dev")
    with col2:
        if status.get('running'):
            st.success("âœ… é€£æ¥æ­£å¸¸")
        else:
            st.error("âŒ é€£æ¥å¤±æ•—")

# ===========================================
# é è…³
# ===========================================
st.divider()
st.markdown("""
<div style="text-align: center; color: #888; font-size: 0.9rem;">
    MediaMiner v1.0 | ä¸€äººå…¬å¸å‰µæ¥­è€…çŸ¥è­˜æå–æ¡†æ¶
</div>
""", unsafe_allow_html=True)
