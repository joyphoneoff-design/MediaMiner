#!/usr/bin/env python3
"""
MediaMiner Streamlit UI
ç¤¾äº¤åª’é«”çŸ¥è­˜æå–ç³»çµ±ä»‹é¢
"""

import os
import sys
from pathlib import Path
from datetime import datetime

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
from dotenv import load_dotenv
load_dotenv(Path(__file__).parent.parent / ".env")

import streamlit as st

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from scrapers.youtube_scraper import YouTubeScraper
from scrapers.transcript_fetcher import TranscriptFetcher
from processors.knowledge_extractor import KnowledgeExtractor
from processors.metadata_injector import MetadataInjector
from integrations.r2r_connector import R2RConnector

# ===========================================
# é é¢é…ç½®
# ===========================================
st.set_page_config(
    page_title="MediaMiner - å‰µæ¥­è€…çŸ¥è­˜åº«",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===========================================
# è‡ªå®šç¾©æ¨£å¼
# ===========================================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        color: #666;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    .stat-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius: 10px;
        padding: 1.5rem;
        text-align: center;
    }
    .stat-number {
        font-size: 2rem;
        font-weight: 700;
        color: #667eea;
    }
    .success-box {
        background: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background: #fff3cd;
        border: 1px solid #ffc107;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ===========================================
# Session State åˆå§‹åŒ–
# ===========================================
if 'videos' not in st.session_state:
    st.session_state.videos = []
if 'processed_count' not in st.session_state:
    st.session_state.processed_count = 0
if 'processing' not in st.session_state:
    st.session_state.processing = False

# ===========================================
# å´é‚Šæ¬„
# ===========================================
with st.sidebar:
    st.markdown("### ğŸ¯ MediaMiner")
    st.markdown("**ç¤¾äº¤åª’é«”çŸ¥è­˜æå–ç³»çµ±**")
    
    st.divider()
    
    # å°èˆª
    page = st.radio(
        "åŠŸèƒ½é¸æ“‡",
        ["ğŸ“º é »é“æ“·å–", "ğŸ“± å°ç´…æ›¸", "ğŸ“Š è™•ç†ç‹€æ…‹", "ğŸ” çŸ¥è­˜å•ç­”", "âš™ï¸ è¨­å®š"],
        label_visibility="collapsed"
    )
    
    st.divider()
    
    # R2R ç‹€æ…‹
    r2r = R2RConnector()
    status = r2r.check_r2r_status()
    if status.get('running'):
        st.success("âœ… R2R é‹è¡Œä¸­")
    else:
        st.warning("âš ï¸ R2R æœªé‹è¡Œ")

# ===========================================
# ä¸»å…§å®¹å€
# ===========================================

# é é¢æ¨™é¡Œ
st.markdown('<h1 class="main-header">ğŸ¯ MediaMiner</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">ä¸€äººå…¬å¸å‰µæ¥­è€…çŸ¥è­˜æå–æ¡†æ¶</p>', unsafe_allow_html=True)

# é »é“æ“·å–é é¢
if page == "ğŸ“º é »é“æ“·å–":
    st.markdown("## ğŸ“º é »é“æ“·å–")
    
    # Session state for video list
    if 'channel_videos' not in st.session_state:
        st.session_state.channel_videos = []
    if 'selected_videos' not in st.session_state:
        st.session_state.selected_videos = set()
    if 'fetch_complete' not in st.session_state:
        st.session_state.fetch_complete = False
    if 'processing' not in st.session_state:
        st.session_state.processing = False
    
    # è¼¸å…¥å€
    channel_url = st.text_input(
        "YouTube é »é“ URL",
        placeholder="https://youtube.com/@DanKoeTalks",
        help="è¼¸å…¥ YouTube é »é“ URL (æ”¯æ´ @username æ ¼å¼)"
    )
    
    st.divider()
    
    # ========== æ­¥é©Ÿ 1: ç²å–å½±ç‰‡åˆ—è¡¨ ==========
    col1, col2 = st.columns([1, 3])
    
    with col1:
        fetch_btn = st.button("ğŸ“‹ ç²å–å½±ç‰‡åˆ—è¡¨", type="secondary")
    
    with col2:
        if st.session_state.fetch_complete:
            st.success(f"âœ… å·²è¼‰å…¥ {len(st.session_state.channel_videos)} éƒ¨å½±ç‰‡")
    
    if fetch_btn and channel_url:
        st.session_state.processing = True
        st.session_state.fetch_complete = False
        
        with st.spinner("ğŸ” æ­£åœ¨ç²å–é »é“å½±ç‰‡åˆ—è¡¨..."):
            scraper = YouTubeScraper()
            max_vids = 0  # 0 = ç²å–å…¨éƒ¨å½±ç‰‡
            videos = scraper.get_channel_videos(channel_url, max_vids)
            
            if videos:
                st.session_state.channel_videos = videos
                
                # é è¨­åƒ…é¸æ“‡æœªè™•ç†çš„å½±ç‰‡ (Smart Select)
                from processors.metadata_injector import MetadataInjector
                temp_injector = MetadataInjector()
                temp_output_dir = Path.home() / "Documents" / "MediaMiner_Data" / "processed"
                unprocessed_indices = set()
                for idx, video in enumerate(videos):
                    filename = temp_injector.generate_safe_filename(video['title'])
                    if not (temp_output_dir / f"{filename}.md").exists():
                        unprocessed_indices.add(idx)
                
                st.session_state.selected_videos = unprocessed_indices  # åƒ…é¸æ“‡æœªè™•ç†
                st.session_state.fetch_complete = True
                st.success(f"âœ… æ‰¾åˆ° {len(videos)} éƒ¨å½±ç‰‡ (ğŸ†• {len(unprocessed_indices)} éƒ¨æœªè™•ç†)")
            else:
                st.error("âŒ ç„¡æ³•ç²å–å½±ç‰‡åˆ—è¡¨ï¼Œè«‹ç¢ºèª URL æ ¼å¼æ­£ç¢º")
        
        st.session_state.processing = False
        st.rerun()
    
    # ========== æ­¥é©Ÿ 2: é¡¯ç¤ºå½±ç‰‡åˆ—è¡¨èˆ‡é¸æ“‡ ==========
    if st.session_state.channel_videos:
        st.markdown("### ğŸ“¹ å½±ç‰‡åˆ—è¡¨")
        
        # å®šç¾© checkbox è®ŠåŒ–è™•ç†å‡½æ•¸ (å·²å»¢æ£„ï¼Œæ”¹ç”¨ç›´æ¥ç‹€æ…‹åŒæ­¥)
        # def toggle_video(idx, version): ...
        
        # åˆå§‹åŒ– MetadataInjector ç”¨æ–¼æª¢æŸ¥å·²è™•ç†æª”æ¡ˆ
        injector = MetadataInjector()
        output_dir = Path.home() / "Documents" / "MediaMiner_Data" / "processed"

        # å…¨é¸/å–æ¶ˆå…¨é¸ (ä½¿ç”¨ç¨ç«‹è¨ˆæ•¸å™¨é¿å… key è¡çª)
        if 'select_version' not in st.session_state:
            st.session_state.select_version = 0
        
        col1, col2, col3, col4 = st.columns([1, 1, 1, 2])
        with col1:
            if st.button("âœ… å…¨é¸ (æœªè™•ç†)", help="åƒ…é¸æ“‡å°šæœªä¸‹è¼‰/è™•ç†éçš„å½±ç‰‡"):
                # Smart Select: åƒ…é¸æ“‡æœªè™•ç†çš„å½±ç‰‡
                new_selection = set()
                for idx, video in enumerate(st.session_state.channel_videos):
                    filename = injector.generate_safe_filename(video['title'])
                    if not (output_dir / f"{filename}.md").exists():
                        new_selection.add(idx)
                
                st.session_state.selected_videos = new_selection
                st.session_state.select_version += 1  # å¼·åˆ¶é‡æ–°ç”Ÿæˆæ‰€æœ‰ checkbox
                st.rerun()
        with col2:
            if st.button("â˜‘ï¸ å¼·åˆ¶å…¨é¸", help="é¸æ“‡åˆ—è¡¨ä¸­çš„æ‰€æœ‰å½±ç‰‡ï¼ˆåŒ…å«å·²è™•ç†ï¼‰"):
                st.session_state.selected_videos = set(range(len(st.session_state.channel_videos)))
                st.session_state.select_version += 1
                st.rerun()
        with col3:
            if st.button("âŒ æ¸…é™¤é¸æ“‡"):
                st.session_state.selected_videos = set()
                st.session_state.select_version += 1
                st.rerun()
        with col4:
            # è¨ˆç®—çµ±è¨ˆ
            total_selected = len(st.session_state.selected_videos)
            processed_in_selection = 0
            for idx in st.session_state.selected_videos:
                if 0 <= idx < len(st.session_state.channel_videos):
                    v = st.session_state.channel_videos[idx]
                    fname = injector.generate_safe_filename(v['title'])
                    if (output_dir / f"{fname}.md").exists():
                        processed_in_selection += 1
            
            new_in_selection = total_selected - processed_in_selection
            st.info(f"å·²é¸ **{total_selected}** éƒ¨ (ğŸ†• {new_in_selection} / âœ… {processed_in_selection})")
        
        # å½±ç‰‡è¡¨æ ¼
        st.markdown("---")
        
        # åˆ†é é¡¯ç¤º (æ¯é  50 å€‹)
        videos = st.session_state.channel_videos
        page_size = 50
        total_pages = (len(videos) - 1) // page_size + 1
        
        if 'video_page' not in st.session_state:
            st.session_state.video_page = 0
        
        # åˆ†é æ§åˆ¶
        col1, col2, col3 = st.columns([1, 2, 1])
        with col1:
            if st.button("â¬…ï¸ ä¸Šä¸€é ", disabled=st.session_state.video_page == 0):
                st.session_state.video_page -= 1
                st.rerun()
        with col2:
            st.markdown(f"<center>ç¬¬ {st.session_state.video_page + 1} / {total_pages} é </center>", unsafe_allow_html=True)
        with col3:
            if st.button("â¡ï¸ ä¸‹ä¸€é ", disabled=st.session_state.video_page >= total_pages - 1):
                st.session_state.video_page += 1
                st.rerun()
        
        # é¡¯ç¤ºç•¶å‰é çš„å½±ç‰‡
        start_idx = st.session_state.video_page * page_size
        end_idx = min(start_idx + page_size, len(videos))
        
        # ä½¿ç”¨ç‰ˆæœ¬è™Ÿä½œç‚º key å‰ç¶´ï¼Œç¢ºä¿å…¨é¸/å–æ¶ˆå…¨é¸å¾Œé‡æ–°ç”Ÿæˆ checkbox
        version = st.session_state.select_version
        
        for i in range(start_idx, end_idx):
            video = videos[i]
            col1, col2, col3, col4 = st.columns([0.5, 4, 1, 1])
            
            with col1:
                # ä½¿ç”¨ç‰ˆæœ¬è™Ÿç¢ºä¿å…¨é¸/å–æ¶ˆå…¨é¸å¾Œ checkbox æ­£ç¢ºæ›´æ–°
                checkbox_key = f"v{version}_vid_{i}"
                is_selected = i in st.session_state.selected_videos
                
                checked = st.checkbox(
                    "", 
                    value=is_selected,
                    key=checkbox_key,
                    label_visibility="collapsed"
                )
                
                # ç›´æ¥ç‹€æ…‹åŒæ­¥ï¼šå¦‚æœ Checkbox ç‹€æ…‹èˆ‡ Set ä¸ä¸€è‡´ï¼Œç«‹å³æ›´æ–°ä¸¦é‡è·‘
                if checked and not is_selected:
                    st.session_state.selected_videos.add(i)
                    st.rerun()
                elif not checked and is_selected:
                    st.session_state.selected_videos.discard(i)
                    st.rerun()
            
            with col2:
                # æª¢æŸ¥æ˜¯å¦å·²è™•ç†
                filename = injector.generate_safe_filename(video['title'])
                is_processed = (output_dir / f"{filename}.md").exists()
                
                title_display = video['title'][:60] + "..." if len(video['title']) > 60 else video['title']
                
                if is_processed:
                    st.markdown(f"**{i+1}.** {title_display} `âœ… å·²å®Œæˆ`")
                else:
                    st.markdown(f"**{i+1}.** {title_display}")
            
            with col3:
                st.caption(video.get('duration_string', 'N/A'))
            
            with col4:
                views = video.get('view_count', 0)
                if views >= 1000000:
                    st.caption(f"{views/1000000:.1f}M ğŸ‘")
                elif views >= 1000:
                    st.caption(f"{views/1000:.0f}K ğŸ‘")
                else:
                    st.caption(f"{views} ğŸ‘")
        
        st.divider()
        
        # ========== æ­¥é©Ÿ 3: é–‹å§‹è™•ç† ==========
        st.markdown("### ğŸš€ é–‹å§‹ä¸‹è¼‰è™•ç†")
        
        # è™•ç†è¨­å®š - ç¬¬ä¸€è¡Œ
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            batch_size = st.slider("æ‰¹æ¬¡å¤§å°", min_value=1, max_value=10, value=10, 
                                   help="æ¯æ‰¹è™•ç†çš„å½±ç‰‡æ•¸é‡")
        with col2:
            whisper_backend = st.selectbox(
                "Whisper å¾Œç«¯",
                options=["groq", "mlx", "openai"],
                format_func=lambda x: {
                    "mlx": "ğŸ–¥ï¸ MLX (æœ¬åœ° GPU)",
                    "groq": "âš¡ Groq API (å…è²»è¶…å¿«)", 
                    "openai": "ğŸ”· OpenAI API (ä»˜è²»)"
                }.get(x, x),
                help="é¸æ“‡èªéŸ³è¾¨è­˜å¾Œç«¯"
            )
        with col3:
            if whisper_backend == "mlx":
                whisper_model = "large-v3-turbo"
                st.info("ğŸ“Œ ä½¿ç”¨ Turbo æ¨¡å‹ (MLX GPU)")
            else:
                whisper_model = "large-v3-turbo"
                st.info("ğŸ“Œ ä½¿ç”¨ turbo æ¨¡å‹")
        with col4:
            if whisper_backend in ["groq", "openai"]:
                api_workers = st.slider("API ä¸¦è¡Œ", min_value=1, max_value=10, value=10,
                                       help="Groq: 30 req/minï¼Œå»ºè­° 5-7 | 10 å¯èƒ½è§¸ç™¼é™é€Ÿ")
            else:
                api_workers = 1
                st.caption("æœ¬åœ°è™•ç†")
        
        # ä¿å­˜è¨­å®šåˆ° session
        st.session_state.whisper_backend = whisper_backend
        st.session_state.whisper_model = whisper_model
        st.session_state.api_workers = api_workers
        
        if st.button("ğŸš€ é–‹å§‹ä¸‹è¼‰å­—å¹•ä¸¦è™•ç†", type="primary", 
                     disabled=len(st.session_state.selected_videos) == 0 or st.session_state.processing):
            
            st.session_state.processing = True
            selected_indices = sorted(st.session_state.selected_videos)
            selected_videos = [st.session_state.channel_videos[i] for i in selected_indices]
            
            st.info(f"ğŸ¬ æº–å‚™è™•ç† {len(selected_videos)} éƒ¨å½±ç‰‡ (æ‰¹æ¬¡å¤§å°: {batch_size})")
            
            progress_bar = st.progress(0, text="åˆå§‹åŒ–...")
            status_container = st.empty()
            metrics_placeholder = st.empty()
            
            try:
                import time
                import gc
                
                # åˆå§‹åŒ–å…ƒä»¶ (æ¯æ‰¹é‡æ–°åˆå§‹åŒ–ä»¥é‡‹æ”¾è¨˜æ†¶é«”)
                output_dir = Path.home() / "Documents" / "MediaMiner_Data" / "processed"
                output_dir.mkdir(parents=True, exist_ok=True)
                
                results = []
                start_time = time.time()
                error_types = {}
                
                # åˆ†æ‰¹è™•ç†
                total_batches = (len(selected_videos) + batch_size - 1) // batch_size
                
                for batch_idx in range(total_batches):
                    batch_start = batch_idx * batch_size
                    batch_end = min(batch_start + batch_size, len(selected_videos))
                    batch_videos = selected_videos[batch_start:batch_end]
                    
                    status_container.info(f"ğŸ“¦ è™•ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} ({len(batch_videos)} éƒ¨å½±ç‰‡)")
                    
                    # æ¯æ‰¹é‡æ–°å»ºç«‹å…ƒä»¶ä»¥é¿å…è¨˜æ†¶é«”ç´¯ç©
                    fetcher = TranscriptFetcher()
                    extractor = KnowledgeExtractor()
                    injector = MetadataInjector()
                    
                    # å®šç¾©å–®å€‹å½±ç‰‡è™•ç†å‡½æ•¸
                    def process_single_video(args):
                        video_idx, video = args
                        result = {'video': video, 'success': False, 'error': None}
                        
                        try:
                            filename = injector.generate_safe_filename(video['title'])
                            output_file = output_dir / f"{filename}.md"
                            
                            # ç²å–é€å­—ç¨¿
                            transcript = fetcher.fetch(
                                video['url'],
                                whisper_backend=st.session_state.get('whisper_backend', 'mlx'),
                                whisper_model=st.session_state.get('whisper_model', 'large-v3-turbo')
                            )
                            
                            if transcript:
                                # æå–çŸ¥è­˜
                                knowledge = extractor.process_transcript(
                                    transcript['text'],
                                    video_info={
                                        'title': video['title'],
                                        'channel': video.get('channel', ''),
                                        'duration': video.get('duration')
                                    }
                                )
                                
                                # ç”Ÿæˆ MD
                                # å°‡è­˜åˆ¥åˆ°çš„ guest æ”¾å…¥ video_info
                                guest = knowledge.get('guest')
                                md_content = injector.create_markdown(
                                    content=transcript['text'],
                                    knowledge=knowledge.get('knowledge', ''),
                                    video_info={
                                        'title': video['title'],
                                        'source': video.get('channel', ''),
                                        'platform': 'youtube',
                                        'url': video['url'],
                                        'duration': video.get('duration'),
                                        'guest': guest  # è¨ªè«‡å˜‰è³“
                                    },
                                    summary=knowledge.get('summary', ''),
                                    keywords=knowledge.get('keywords', []),
                                    entities=knowledge.get('entities', []),
                                    tags=knowledge.get('tags', [])
                                )
                                
                                output_file.write_text(md_content, encoding='utf-8')
                                result = {
                                    'video': video, 
                                    'success': True, 
                                    'file': str(output_file),
                                    'source': transcript.get('source', 'unknown')
                                }
                            else:
                                result['error'] = 'ç„¡æ³•ç²å–å­—å¹•'
                        except Exception as e:
                            result['error'] = str(e)[:50]
                        
                        return video_idx, result
                    
                    # æ ¹æ“šå¾Œç«¯é¸æ“‡è™•ç†æ–¹å¼
                    if whisper_backend in ['groq', 'openai'] and api_workers > 1:
                        # === API å¾Œç«¯ï¼šå¤šç·šç¨‹ä¸¦è¡Œè™•ç† ===
                        from concurrent.futures import ThreadPoolExecutor, as_completed
                        
                        status_container.info(f"ğŸ“¦ æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} - å¤šç·šç¨‹è™•ç† ({api_workers} workers)")
                        
                        with ThreadPoolExecutor(max_workers=api_workers) as executor:
                            futures = {
                                executor.submit(process_single_video, (batch_start + i, video)): i 
                                for i, video in enumerate(batch_videos)
                            }
                            
                            for future in as_completed(futures):
                                video_idx, result = future.result()
                                results.append(result)
                                
                                if result['success']:
                                    st.session_state.processed_count += 1
                                else:
                                    error_msg = result.get('error', 'æœªçŸ¥éŒ¯èª¤')
                                    error_types[error_msg] = error_types.get(error_msg, 0) + 1
                                
                                # æ›´æ–°é€²åº¦
                                progress = int((len(results) / len(selected_videos)) * 100)
                                progress_bar.progress(progress, text=f"è™•ç†: {len(results)}/{len(selected_videos)}")
                    else:
                        # === MLX å¾Œç«¯ï¼šä¸²è¡Œè™•ç†ï¼ˆå„ªåŒ– GPU ä½¿ç”¨ï¼‰ ===
                        for i, video in enumerate(batch_videos):
                            video_idx = batch_start + i + 1
                            progress = int((video_idx / len(selected_videos)) * 100)
                            progress_bar.progress(progress, text=f"è™•ç†: {video_idx}/{len(selected_videos)} - {video['title'][:30]}...")
                            
                            _, result = process_single_video((batch_start + i, video))
                            results.append(result)
                            
                            if result['success']:
                                st.session_state.processed_count += 1
                            else:
                                error_msg = result.get('error', 'æœªçŸ¥éŒ¯èª¤')
                                error_types[error_msg] = error_types.get(error_msg, 0) + 1
                        

                    
                    # æ‰¹æ¬¡å®Œæˆå¾Œæ¸…ç†è¨˜æ†¶é«”
                    del fetcher, extractor, injector
                    gc.collect()
                    
                    # æ‰¹æ¬¡é–“çŸ­æš«ä¼‘æ¯é¿å…é€Ÿç‡é™åˆ¶
                    if batch_idx < total_batches - 1:
                        time.sleep(1)
                
                # è¨ˆç®—åŸ·è¡Œçµ±è¨ˆ
                elapsed_time = time.time() - start_time
                success_count = sum(1 for r in results if r['success'])
                fail_count = len(results) - success_count
                
                progress_bar.progress(100, text="âœ… å®Œæˆ!")
                
                # é¡¯ç¤ºçµ±è¨ˆæŒ‡æ¨™ (ç°¡åŒ–ç‰ˆï¼Œå› ç‚ºä¸å†è·³éä»»ä½•æª”æ¡ˆ)
                with metrics_placeholder.container():
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("âœ… æˆåŠŸ", f"{success_count}/{len(results)}")
                    with col2:
                        st.metric("âŒ å¤±æ•—", fail_count)
                    with col3:
                        st.metric("â±ï¸ è€—æ™‚", f"{elapsed_time:.1f}s")
                    
                    # é¡¯ç¤ºéŒ¯èª¤åˆ†å¸ƒ
                    if error_types:
                        st.markdown("**éŒ¯èª¤é¡å‹åˆ†å¸ƒ:**")
                        for err, count in sorted(error_types.items(), key=lambda x: -x[1])[:5]:
                            st.caption(f"  â€¢ {err}: {count} æ¬¡")
                
                # é¡¯ç¤ºçµæœ
                if success_count > 0:
                    st.success(f"ğŸ‰ å®Œæˆ! æˆåŠŸè™•ç† {success_count}/{len(selected_videos)} éƒ¨å½±ç‰‡")
                else:
                    st.error(f"âŒ è™•ç†å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–ç¨å¾Œå†è©¦")
                
                with st.expander("ğŸ“‹ è™•ç†çµæœè©³æƒ…"):
                    for r in results:
                        if r['success']:
                            st.markdown(f"âœ… **{r['video']['title'][:50]}...**")
                        else:
                            st.markdown(f"âŒ **{r['video']['title'][:50]}...** - {r.get('error', '')}")
                
            except Exception as e:
                st.error(f"âŒ éŒ¯èª¤: {str(e)}")
            finally:
                st.session_state.processing = False

# å°ç´…æ›¸æ“·å–é é¢
elif page == "ğŸ“± å°ç´…æ›¸":
    st.markdown("## ğŸ“± å°ç´…æ›¸æ“·å–")
    
    st.info("""
    **ä½¿ç”¨æ–¹å¼**ï¼šè²¼ä¸Šå°ç´…æ›¸ç­†è¨˜é€£çµï¼ˆæ”¯æ´ xhslink.com çŸ­ç¶²å€ï¼‰
    
    ğŸ’¡ å¦‚ä½•ç²å–é€£çµï¼šåœ¨å°ç´…æ›¸ App æˆ–ç¶²é ç‰ˆï¼Œé»æ“Šã€Œåˆ†äº«ã€â†’ã€Œè¤‡è£½é€£çµã€
    """)
    
    # Session state for XHS notes
    if 'xhs_notes' not in st.session_state:
        st.session_state.xhs_notes = []
    if 'xhs_selected' not in st.session_state:
        st.session_state.xhs_selected = set()
    
    st.divider()
    
    # ========== æ–¹å¼ A: å¾ç”¨æˆ¶ä¸»é ç²å–ç­†è¨˜åˆ—è¡¨ ==========
    st.markdown("### ğŸ“¥ æ–¹å¼ A: å¾ç”¨æˆ¶ä¸»é ç²å–")
    
    # Chrome Debug æ¨¡å¼èªªæ˜
    with st.expander("ğŸ’¡ å¦‚ä½•å•Ÿç”¨å®Œæ•´ç²å–æ¨¡å¼ï¼ˆæ¨è–¦ï¼‰", expanded=False):
        st.markdown("""
        **Chrome Debug æ¨¡å¼å¯è®“ç³»çµ±ä½¿ç”¨æ‚¨çš„ç™»å…¥ç‹€æ…‹ç²å–å®Œæ•´ç­†è¨˜åˆ—è¡¨ï¼š**
        
        1. **å®Œå…¨é—œé–‰ Chrome**ï¼ˆCommand+Qï¼‰
        2. **åŸ·è¡Œä»¥ä¸‹çµ‚ç«¯å‘½ä»¤**ï¼š
        ```bash
        /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222
        ```
        3. **åœ¨ Chrome ä¸­ç™»å…¥å°ç´…æ›¸**
        4. è¿”å›æ­¤é é¢ï¼Œè¼¸å…¥ä¸»é  URL ä¸¦é»æ“Šã€Œç²å–ç­†è¨˜åˆ—è¡¨ã€
        """)
    
    with st.form("xhs_profile_form"):
        profile_url = st.text_input(
            "è¼¸å…¥å°ç´…æ›¸ç”¨æˆ¶ä¸»é  URL",
            placeholder="https://www.xiaohongshu.com/user/profile/xxx æˆ– xhslink.com/xxx",
            help="æ”¯æŒå®Œæ•´ä¸»é  URL æˆ–åˆ†äº«çš„çŸ­é€£çµ"
        )
        col_a1, col_a2 = st.columns([1, 1])
        with col_a1:
            max_notes = st.number_input("æœ€å¤§ç­†è¨˜æ•¸", min_value=0, max_value=500, value=0, step=10, help="0 = ç²å–å…¨éƒ¨")
        with col_a2:
            fetch_profile_btn = st.form_submit_button("ğŸ” ç²å–ç­†è¨˜åˆ—è¡¨", type="secondary", use_container_width=True)
    
    if fetch_profile_btn and profile_url:
        with st.spinner("æ­£åœ¨ç²å–ç­†è¨˜åˆ—è¡¨..."):
            from scrapers.xiaohongshu_scraper import XiaohongshuScraper
            scraper = XiaohongshuScraper()
            
            # å˜—è©¦ç²å–ç­†è¨˜
            notes = scraper.get_user_notes(profile_url, max_notes=max_notes)
            
            if notes:
                st.session_state.xhs_notes = notes
                st.session_state.xhs_selected = set(range(len(notes)))
                st.success(f"âœ… æ‰¾åˆ° {len(notes)} å€‹ç­†è¨˜")
                st.rerun()
            else:
                st.warning("""
                âš ï¸ **ç„¡æ³•è‡ªå‹•ç²å–ç­†è¨˜åˆ—è¡¨**
                
                å°ç´…æ›¸é™åˆ¶äº†æœªç™»å…¥ç”¨æˆ¶çš„è¨ªå•ã€‚è«‹ä½¿ç”¨ä»¥ä¸‹æ›¿ä»£æ–¹æ¡ˆ:
                1. åœ¨ç€è¦½å™¨ä¸­ç™»å…¥å°ç´…æ›¸
                2. è¨ªå•ç”¨æˆ¶ä¸»é ï¼Œæ‰‹å‹•è¤‡è£½æƒ³è¦çš„ç­†è¨˜é€£çµ
                3. è²¼åˆ°ä¸‹æ–¹ã€Œæ–¹å¼ Bã€çš„è¼¸å…¥æ¡†ä¸­
                """)
                
                # æä¾›å¿«æ·æŒ‰éˆ•æ‰“é–‹ä¸»é 
                import webbrowser
                if st.button(f"ğŸŒ åœ¨ç€è¦½å™¨ä¸­æ‰“é–‹ä¸»é "):
                    webbrowser.open(profile_url)
    
    st.divider()
    
    # ========== æ–¹å¼ B: è²¼ä¸Šç­†è¨˜é€£çµ ==========
    st.markdown("### ğŸ“‹ æ–¹å¼ B: è²¼ä¸Šç­†è¨˜é€£çµ")
    with st.form("xhs_url_form"):
        raw_text = st.text_area(
            "è²¼ä¸ŠåŒ…å«ç­†è¨˜é€£çµçš„æ–‡å­—",
            placeholder="ä¾‹å¦‚:\nåˆ†äº«ä¸€å€‹å¾ˆæ£’çš„å‰µæ¥­å¿ƒå¾— https://xhslink.com/xxx\nå¦ä¸€å€‹å¥½å…§å®¹ https://www.xiaohongshu.com/explore/yyy",
            height=150
        )
        col1, col2 = st.columns([3, 1])
        with col1:
            parse_btn = st.form_submit_button("ğŸ“‹ è§£æé€£çµ", type="secondary")
        with col2:
            fetch_titles = st.checkbox("ç²å–çœŸå¯¦æ¨™é¡Œ", value=False, help="è¼ƒæ…¢ä½†é¡¯ç¤ºå½±ç‰‡çœŸå¯¦æ¨™é¡Œ")
    
    if parse_btn and raw_text:
        # æå– URL
        import re
        import subprocess
        url_pattern = re.compile(r'https?://[^\s,;"\'\<\>]+')
        all_urls = url_pattern.findall(raw_text)
        
        # éæ¿¾å‡ºå°ç´…æ›¸ç›¸é—œé€£çµ
        xhs_urls = [url for url in all_urls if 'xhslink.com' in url or 'xiaohongshu.com' in url]
        
        if xhs_urls:
            notes = []
            progress_text = st.empty()
            
            if fetch_titles:
                # === å¤šç·šç¨‹ç²å–çœŸå¯¦æ¨™é¡Œ ===
                from concurrent.futures import ThreadPoolExecutor
                
                def get_title(args):
                    i, url = args
                    title = None
                    
                    # ç­–ç•¥ 1: å„ªå…ˆå¾è¼¸å…¥æ–‡å­—æå–ï¼ˆæœ€å¯é ï¼‰
                    lines = raw_text.split('\n')
                    for line in lines:
                        if url in line:
                            before_url = line.split(url)[0].strip()
                            if before_url and len(before_url) > 2:
                                title = before_url[:60]
                                break
                    
                    # ç­–ç•¥ 2: è‹¥ç„¡æ–‡å­—ï¼Œä½¿ç”¨ yt-dlp ç²å–çœŸå¯¦æ¨™é¡Œ
                    if not title:
                        try:
                            result = subprocess.run(
                                ["yt-dlp", "--get-title", "--cookies-from-browser", "chrome", 
                                 "--no-warnings", "--ignore-errors", url],
                                capture_output=True, text=True, timeout=25
                            )
                            if result.returncode == 0 and result.stdout.strip():
                                title = result.stdout.strip()[:60]
                        except Exception:
                            pass
                    
                    return i, url, title if title else f'å°ç´…æ›¸ç­†è¨˜ #{i+1}'
                
                progress_text.info(f"ğŸ” å¤šç·šç¨‹è§£æä¸­ ({len(xhs_urls)} å€‹é€£çµ)...")
                
                with ThreadPoolExecutor(max_workers=10) as executor:
                    results = list(executor.map(get_title, enumerate(xhs_urls)))
                
                for i, url, title in sorted(results, key=lambda x: x[0]):
                    notes.append({
                        'title': title,
                        'url': url,
                        'note_id': url.split('/')[-1][:10] if '/' in url else f'note_{i}',
                        'type': 'video'
                    })
            else:
                # === å¿«é€Ÿæ¨¡å¼ï¼šå¾è¼¸å…¥æ–‡å­—æå–æˆ–ä½¿ç”¨ç·¨è™Ÿ ===
                for i, url in enumerate(xhs_urls):
                    title = None
                    lines = raw_text.split('\n')
                    for line in lines:
                        if url in line:
                            before_url = line.split(url)[0].strip()
                            if before_url and len(before_url) > 2:
                                title = before_url[:50]
                                break
                    
                    if not title:
                        title = f'å°ç´…æ›¸ç­†è¨˜ #{i+1}'
                    
                    notes.append({
                        'title': title,
                        'url': url,
                        'note_id': url.split('/')[-1][:10] if '/' in url else f'note_{i}',
                        'type': 'video'
                    })
            
            progress_text.empty()
            st.session_state.xhs_notes = notes
            st.session_state.xhs_selected = set(range(len(notes)))
            st.success(f"âœ… æ‰¾åˆ° {len(notes)} å€‹å°ç´…æ›¸é€£çµ")
            st.rerun()
        else:
            st.error("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å°ç´…æ›¸é€£çµ")
    
    # ========== æ­¥é©Ÿ 2: é¡¯ç¤ºé€£çµåˆ—è¡¨èˆ‡é¸æ“‡ ==========
    if st.session_state.xhs_notes:
        st.markdown("### ğŸ“ é€£çµåˆ—è¡¨")
        
        # å…¨é¸/æ¸…é™¤æŒ‰éˆ•
        col1, col2 = st.columns(2)
        with col1:
            select_all = st.button("âœ… å…¨é¸", key="xhs_select_all", use_container_width=True)
        with col2:
            clear_all = st.button("âŒ æ¸…é™¤", key="xhs_clear_all", use_container_width=True)
        
        # è™•ç†æŒ‰éˆ•é»æ“Š
        if select_all:
            for i in range(len(st.session_state.xhs_notes)):
                st.session_state.xhs_selected.add(i)
            st.rerun()
        if clear_all:
            st.session_state.xhs_selected.clear()
            st.rerun()
        
        # é¡¯ç¤ºé€£çµåˆ—è¡¨ - ä½¿ç”¨ callback ç¢ºä¿ç‹€æ…‹åŒæ­¥
        def toggle_selection(idx):
            if idx in st.session_state.xhs_selected:
                st.session_state.xhs_selected.discard(idx)
            else:
                st.session_state.xhs_selected.add(idx)
        
        for idx, note in enumerate(st.session_state.xhs_notes):
            checkbox_key = f"xhs_note_{idx}"
            
            # ç¢ºä¿ session state åˆå§‹åŒ–
            if checkbox_key not in st.session_state:
                st.session_state[checkbox_key] = idx in st.session_state.xhs_selected
            
            # ä½¿ç”¨ on_change å›èª¿åŒæ­¥ç‹€æ…‹
            def on_checkbox_change(note_idx, key):
                if st.session_state[key]:
                    st.session_state.xhs_selected.add(note_idx)
                else:
                    st.session_state.xhs_selected.discard(note_idx)
            
            st.checkbox(
                f"**{note['title']}** - `{note['url'][:50]}...`",
                key=checkbox_key,
                on_change=on_checkbox_change,
                args=(idx, checkbox_key)
            )
        
        st.caption(f"**å·²é¸æ“‡: {len(st.session_state.xhs_selected)}/{len(st.session_state.xhs_notes)}**")
        
        st.divider()
        
        # ========== æ­¥é©Ÿ 3: é–‹å§‹è™•ç† ==========
        st.markdown("### ğŸ¬ é–‹å§‹è™•ç†")
        
        # è™•ç†è¨­å®š (å°æ¨™ YouTube é é¢)
        with st.expander("âš™ï¸ è™•ç†è¨­å®š", expanded=True):
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                xhs_batch_size = st.slider("æ‰¹æ¬¡å¤§å°", min_value=1, max_value=10, value=5,
                                           help="æ¯æ‰¹è™•ç†çš„ç­†è¨˜æ•¸é‡", key="xhs_batch_size")
            with col2:
                xhs_whisper_backend = st.selectbox(
                    "Whisper å¾Œç«¯",
                    options=["groq", "mlx", "openai"],
                    format_func=lambda x: {
                        "groq": "âš¡ Groq (å…è²»è¶…å¿«)",
                        "mlx": "ğŸ–¥ï¸ MLX (æœ¬åœ° GPU)", 
                        "openai": "ğŸ”· OpenAI (ä»˜è²»)"
                    }.get(x, x),
                    key="xhs_whisper_backend"
                )
            with col3:
                if xhs_whisper_backend in ["groq", "openai"]:
                    xhs_api_workers = st.slider("API ä¸¦è¡Œ", min_value=1, max_value=5, value=3,
                                                help="API ä¸¦è¡Œè«‹æ±‚æ•¸ (å»ºè­° 3)", key="xhs_api_workers")
                else:
                    xhs_api_workers = 1
                    st.caption("ğŸ–¥ï¸ æœ¬åœ°è™•ç†")
            with col4:
                xhs_auto_cleanup = st.selectbox(
                    "è‡¨æ™‚æª”æ¸…ç†",
                    options=["å³æ™‚åˆªé™¤", "ä¿ç•™3å¤©", "ä¸åˆªé™¤"],
                    index=0,
                    help="è™•ç†å®Œæˆå¾Œå¦‚ä½•è™•ç†éŸ³é »æª”",
                    key="xhs_auto_cleanup"
                )
        
        if st.button("ğŸš€ é–‹å§‹ä¸‹è¼‰ä¸¦è™•ç†", type="primary", 
                     disabled=len(st.session_state.xhs_selected) == 0 or st.session_state.processing,
                     key="xhs_start_process"):
            
            st.session_state.processing = True
            selected_notes = [st.session_state.xhs_notes[i] for i in sorted(st.session_state.xhs_selected)]
            
            # åˆå§‹åŒ–è™•ç†å™¨
            from scrapers.xiaohongshu_scraper import XiaohongshuScraper
            from scrapers.transcript_fetcher import TranscriptFetcher
            from processors.knowledge_extractor import KnowledgeExtractor
            from processors.metadata_injector import MetadataInjector
            
            output_dir = Path.home() / "Documents" / "MediaMiner_Data" / "processed"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            progress_bar = st.progress(0, text="æº–å‚™ä¸­...")
            status_placeholder = st.empty()  # è©³ç´°ç‹€æ…‹é¡¯ç¤º
            metrics_placeholder = st.empty()
            
            results = []
            import time
            start_time = time.time()
            
            try:
                fetcher = TranscriptFetcher()
                extractor = KnowledgeExtractor()
                injector = MetadataInjector()
                
                # æ¸…ç†éæœŸè‡¨æ™‚æª”æ¡ˆ (ä¿ç•™3å¤©æ¨¡å¼)
                if xhs_auto_cleanup == "ä¿ç•™3å¤©":
                    fetcher.cleanup_temp_files(max_age_days=3)
                
                # ç”¨æ–¼é¡¯ç¤ºç•¶å‰ç‹€æ…‹çš„è®Šæ•¸
                current_status = {"msg": "æº–å‚™ä¸­...", "steps": []}
                
                # === å–®ç­†è™•ç†å‡½æ•¸ï¼ˆåŒ…å«æ­¥é©Ÿè¨˜éŒ„ï¼‰===
                def process_single_note(note, note_idx=0, total=1):
                    steps = []  # æ”¶é›†è™•ç†æ­¥é©Ÿ
                    
                    try:
                        # é€²åº¦å›èª¿å‡½æ•¸ - è¨˜éŒ„æ­¥é©Ÿ
                        def on_progress(msg):
                            steps.append(msg)
                            current_status["msg"] = f"[{note_idx+1}/{total}] {note['title'][:15]}... | {msg}"
                        
                        on_progress("ğŸ“¥ é–‹å§‹è™•ç†...")
                        
                        transcript = fetcher.fetch(
                            note['url'],
                            whisper_backend=xhs_whisper_backend,
                            whisper_model='large-v3-turbo',
                            progress_callback=on_progress
                        )
                        
                        if transcript:
                            on_progress("ğŸ“ çŸ¥è­˜æå–ä¸­...")
                            knowledge_result = extractor.process_transcript(
                                transcript['text'],
                                video_info={
                                    'title': note['title'],
                                    'channel': 'å°ç´…æ›¸',
                                    'duration': None
                                }
                            )
                            
                            knowledge_str = knowledge_result.get('knowledge', '') if isinstance(knowledge_result, dict) else str(knowledge_result)
                            
                            on_progress("ğŸ’¾ å¯«å…¥æª”æ¡ˆä¸­...")
                            filename = injector.generate_safe_filename(note['title'])
                            output_file = output_dir / f"{filename}.md"
                            
                            # æå–è­˜åˆ¥åˆ°çš„ guest
                            guest = knowledge_result.get('guest') if isinstance(knowledge_result, dict) else None
                            
                            md_content = injector.create_markdown(
                                content=transcript.get('text', ''),
                                knowledge=knowledge_str,
                                video_info={
                                    'title': note['title'],
                                    'url': note['url'],
                                    'source': 'å°ç´…æ›¸',
                                    'platform': 'xiaohongshu',
                                    'guest': guest  # è¨ªè«‡å˜‰è³“
                                },
                                summary=knowledge_result.get('summary', '') if isinstance(knowledge_result, dict) else '',
                                keywords=knowledge_result.get('keywords', []) if isinstance(knowledge_result, dict) else [],
                                entities=knowledge_result.get('entities', []) if isinstance(knowledge_result, dict) else [],
                                tags=knowledge_result.get('tags', []) if isinstance(knowledge_result, dict) else []
                            )
                            
                            output_file.write_text(md_content, encoding='utf-8')
                            on_progress("âœ… å®Œæˆ!")
                            return {'note': note, 'success': True, 'file': str(output_file), 'steps': steps}
                        else:
                            on_progress("âŒ ç„¡æ³•ç²å–é€å­—ç¨¿")
                            return {'note': note, 'success': False, 'error': 'ç„¡æ³•ç²å–é€å­—ç¨¿ï¼ˆå¯èƒ½æ˜¯ç´”åœ–ç‰‡ç­†è¨˜ï¼‰', 'steps': steps}
                            
                    except Exception as e:
                        steps.append(f"âŒ éŒ¯èª¤: {str(e)[:50]}")
                        return {'note': note, 'success': False, 'error': str(e)[:100], 'steps': steps}
                
                # === å¤šç·šç¨‹è™•ç† (APIæ¨¡å¼) / ä¸²è¡Œè™•ç† (æœ¬åœ°æ¨¡å¼) ===
                from concurrent.futures import ThreadPoolExecutor, as_completed
                
                total_notes = len(selected_notes)
                log_container = st.container()  # ç”¨æ–¼é¡¯ç¤ºè™•ç†æ—¥èªŒ
                
                if xhs_whisper_backend in ["groq", "openai"] and xhs_api_workers > 1:
                    # å¤šç·šç¨‹ä¸¦è¡Œè™•ç†
                    with ThreadPoolExecutor(max_workers=xhs_api_workers) as executor:
                        futures = {executor.submit(process_single_note, note, i, total_notes): (i, note) 
                                   for i, note in enumerate(selected_notes)}
                        completed = 0
                        for future in as_completed(futures):
                            completed += 1
                            progress = int((completed / total_notes) * 100)
                            idx, note = futures[future]
                            result = future.result()
                            
                            progress_bar.progress(progress, text=f"âœ… å®Œæˆ: {completed}/{total_notes}")
                            
                            # é¡¯ç¤ºè©²ç­†è¨˜çš„è™•ç†æ­¥é©Ÿ
                            with log_container:
                                steps_str = " â†’ ".join(result.get('steps', []))
                                if result['success']:
                                    st.success(f"**[{completed}] {note['title'][:25]}...** | {steps_str}")
                                else:
                                    st.error(f"**[{completed}] {note['title'][:25]}...** | {steps_str}")
                            
                            results.append(result)
                            if result['success']:
                                pass  # æˆåŠŸè¨ˆæ•¸å·²åœ¨ä¸Šæ–¹è™•ç†
                else:
                    # ä¸²è¡Œè™•ç†
                    for i, note in enumerate(selected_notes):
                        progress_bar.progress(int((i / total_notes) * 100), text=f"è™•ç†: {i+1}/{total_notes} - {note['title'][:20]}...")
                        status_placeholder.info(f"ğŸ”„ è™•ç†ä¸­: {note['title'][:30]}...")
                        
                        result = process_single_note(note, i, total_notes)
                        
                        # é¡¯ç¤ºè©²ç­†è¨˜çš„è™•ç†æ­¥é©Ÿ
                        progress_bar.progress(int(((i+1) / total_notes) * 100), text=f"âœ… å®Œæˆ: {i+1}/{total_notes}")
                        with log_container:
                            steps_str = " â†’ ".join(result.get('steps', []))
                            if result['success']:
                                st.success(f"**[{i+1}] {note['title'][:25]}...** | {steps_str}")
                            else:
                                st.error(f"**[{i+1}] {note['title'][:25]}...** | {steps_str}")
                        
                        results.append(result)
                        if result['success']:
                            pass  # æˆåŠŸè¨ˆæ•¸å·²åœ¨ä¸Šæ–¹è™•ç†
                
                status_placeholder.empty()
                
                # çµ±è¨ˆçµæœ
                elapsed_time = time.time() - start_time
                success_count = sum(1 for r in results if r['success'])
                
                progress_bar.progress(100, text="âœ… å®Œæˆ!")
                
                with metrics_placeholder.container():
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("âœ… æˆåŠŸ", f"{success_count}/{len(results)}")
                    with col2:
                        st.metric("âŒ å¤±æ•—", len(results) - success_count)
                    with col3:
                        st.metric("â±ï¸ è€—æ™‚", f"{elapsed_time:.1f}s")
                
                if success_count > 0:
                    st.success(f"ğŸ‰ å®Œæˆ! æˆåŠŸè™•ç† {success_count}/{len(selected_notes)} å€‹ç­†è¨˜")
                else:
                    st.warning("âš ï¸ è™•ç†å¤±æ•—ã€‚å°ç´…æ›¸ç­†è¨˜å¯èƒ½æ˜¯ç´”åœ–ç‰‡ï¼Œç„¡æ³•æå–èªéŸ³é€å­—ç¨¿ã€‚")
                
                # é¡¯ç¤ºå¤±æ•—è©³æƒ…
                failed_results = [r for r in results if not r['success']]
                if failed_results:
                    with st.expander("ğŸ“‹ å¤±æ•—è©³æƒ…", expanded=True):
                        for r in failed_results:
                            st.error(f"**{r['note']['title']}**: {r.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                    
            except Exception as e:
                st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                import traceback
                st.code(traceback.format_exc(), language="text")
            finally:
                st.session_state.processing = False

# è™•ç†ç‹€æ…‹é é¢
elif page == "ğŸ“Š è™•ç†ç‹€æ…‹":
    st.markdown("## ğŸ“Š è™•ç†ç‹€æ…‹")
    
    # ç›®éŒ„çµ±è¨ˆ
    data_dir = Path.home() / "Documents" / "MediaMiner_Data"
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        raw_count = len(list((data_dir / "raw").glob("*"))) if (data_dir / "raw").exists() else 0
        st.metric("ğŸ“¥ åŸå§‹æª”æ¡ˆ", raw_count)
    
    with col2:
        processed_count = len(list((data_dir / "processed").glob("*.md"))) if (data_dir / "processed").exists() else 0
        st.metric("âœ… å·²è™•ç†", processed_count)
    
    with col3:
        knowledge_count = len(list((data_dir / "knowledge").glob("*.md"))) if (data_dir / "knowledge").exists() else 0
        st.metric("ğŸ“š çŸ¥è­˜å¡ç‰‡", knowledge_count)
    
    st.divider()
    
    # æœ€è¿‘è™•ç†çš„æª”æ¡ˆ
    st.markdown("### ğŸ“„ æœ€è¿‘è™•ç†çš„æª”æ¡ˆ")
    
    processed_dir = data_dir / "processed"
    if processed_dir.exists():
        files = sorted(processed_dir.glob("*.md"), key=lambda x: x.stat().st_mtime, reverse=True)[:10]
        
        for f in files:
            mtime = datetime.fromtimestamp(f.stat().st_mtime).strftime("%Y-%m-%d %H:%M")
            with st.expander(f"ğŸ“„ {f.name} ({mtime})"):
                content = f.read_text(encoding='utf-8')
                st.markdown(content[:2000] + "..." if len(content) > 2000 else content)
    else:
        st.info("ğŸ“­ é‚„æ²’æœ‰è™•ç†éçš„æª”æ¡ˆ")

# çŸ¥è­˜å•ç­”é é¢
elif page == "ğŸ” çŸ¥è­˜å•ç­”":
    st.markdown("## ğŸ” çŸ¥è­˜å•ç­”")
    
    # å•ç­”è¼¸å…¥
    query = st.text_input(
        "è¼¸å…¥æ‚¨çš„å•é¡Œ",
        placeholder="ä¾‹å¦‚ï¼šä»€éº¼æ˜¯å•†æ¥­æ¨¡å¼ç•«å¸ƒï¼Ÿå¦‚ä½•å»ºç«‹å€‹äººå“ç‰Œï¼Ÿ"
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ” æœ¬åœ°æœç´¢", type="primary"):
            if query:
                with st.spinner("æœç´¢ä¸­..."):
                    # æœ¬åœ°æª”æ¡ˆæœç´¢
                    knowledge_dir = Path.home() / "Documents" / "MediaMiner_Data" / "knowledge"
                    results = []
                    
                    if knowledge_dir.exists():
                        for f in knowledge_dir.glob("*.md"):
                            content = f.read_text(encoding='utf-8')
                            if query.lower() in content.lower():
                                results.append({
                                    'file': f.name,
                                    'content': content[:1000]
                                })
                    
                    if results:
                        st.markdown("### ğŸ“‹ æœç´¢çµæœ")
                        for r in results:
                            with st.expander(f"ğŸ“„ {r['file']}"):
                                st.markdown(r['content'])
                    else:
                        st.info("æœªæ‰¾åˆ°ç›¸é—œå…§å®¹")
    
    with col2:
        if st.button("ğŸ§  AI å•ç­”"):
            if query:
                with st.spinner("AI æ€è€ƒä¸­..."):
                    # ä½¿ç”¨ LLM ç›´æ¥å›ç­”
                    try:
                        from processors.llm_client import get_llm_client
                        
                        # è®€å–æ‰€æœ‰çŸ¥è­˜å¡ç‰‡ä½œç‚ºä¸Šä¸‹æ–‡
                        knowledge_dir = Path.home() / "Documents" / "MediaMiner_Data" / "knowledge"
                        context = ""
                        if knowledge_dir.exists():
                            for f in list(knowledge_dir.glob("*.md"))[:5]:
                                context += f.read_text(encoding='utf-8')[:2000] + "\n\n"
                        
                        client = get_llm_client()
                        prompt = f"""
åŸºæ–¼ä»¥ä¸‹çŸ¥è­˜åº«å…§å®¹å›ç­”å•é¡Œï¼š

{context[:6000]}

å•é¡Œï¼š{query}

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
"""
                        answer = client.generate(
                            prompt=prompt,
                            system_prompt="ä½ æ˜¯ä¸€ä½å•†æ¥­çŸ¥è­˜å°ˆå®¶ï¼Œè«‹æ ¹æ“šæä¾›çš„çŸ¥è­˜å…§å®¹å›ç­”å•é¡Œã€‚",
                            max_tokens=1000
                        )
                        
                        if answer:
                            st.markdown("### ğŸ’¡ AI å›ç­”")
                            st.markdown(answer)
                        else:
                            st.error("ç„¡æ³•ç²å–å›ç­”")
                    except Exception as e:
                        st.error(f"éŒ¯èª¤: {str(e)}")
    
    # R2R ç‹€æ…‹æç¤º
    with st.expander("â„¹ï¸ é—œæ–¼ R2R"):
        st.markdown("""
        **R2R å‘é‡æœç´¢** ç›®å‰æœªå•Ÿç”¨
        
        - æœ¬åœ°æœç´¢ï¼šåŸºæ–¼é—œéµå­—åŒ¹é…
        - AI å•ç­”ï¼šä½¿ç”¨ LLM ç›´æ¥åˆ†æçŸ¥è­˜å¡ç‰‡
        - RAG æœç´¢ï¼šéœ€è¦å•Ÿå‹• R2R æœå‹™
        """)

# è¨­å®šé é¢
elif page == "âš™ï¸ è¨­å®š":
    st.markdown("## âš™ï¸ è¨­å®š")
    
    # API å¯†é‘°è¨­å®š
    st.markdown("### ğŸ”‘ API å¯†é‘°")
    
    with st.expander("Gemini API"):
        gemini_key = st.text_input("Gemini API Key", type="password", 
                                    value=os.getenv("GEMINI_API_KEY", ""))
        gemini_key_backup = st.text_input("Gemini Backup Key", type="password",
                                           value=os.getenv("GEMINI_API_KEY_BACKUP", ""))
    
    with st.expander("Cerebras API"):
        cerebras_key = st.text_input("Cerebras API Key", type="password",
                                      value=os.getenv("CEREBRAS_API_KEY", ""))
    
    with st.expander("OpenAI API"):
        openai_key = st.text_input("OpenAI API Key", type="password",
                                    value=os.getenv("OPENAI_API_KEY", ""))
    
    st.divider()
    
    # R2R è¨­å®š
    st.markdown("### ğŸ—„ï¸ R2R é…ç½®")
    
    r2r = R2RConnector()
    status = r2r.check_r2r_status()
    
    col1, col2 = st.columns(2)
    with col1:
        st.text_input("Collection Name", value="crawl_r2r_dev")
    with col2:
        if status.get('running'):
            st.success("âœ… é€£æ¥æ­£å¸¸")
        else:
            st.error("âŒ é€£æ¥å¤±æ•—")

# ===========================================
# é è…³
# ===========================================
st.divider()
st.markdown("""
<div style="text-align: center; color: #888; font-size: 0.9rem;">
    MediaMiner v1.0 | ä¸€äººå…¬å¸å‰µæ¥­è€…çŸ¥è­˜æå–æ¡†æ¶
</div>
""", unsafe_allow_html=True)
